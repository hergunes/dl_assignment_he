{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Deep Learning<br><br>Assignment-1 (ANN)<br><br>Churn Prediction for Bank Customer<br><h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset in which there are details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer.\n",
    "\n",
    "The features in the given dataset are:\n",
    "- **rownumber:** Row Numbers from 1 to 10000.\n",
    "- **customerid:** A unique ID that identifies each customer.\n",
    "- **surname:** The customer’s surname.\n",
    "- **creditscore:** A credit score is a number between 300–850 that depicts a consumer's creditworthiness.\n",
    "- **geography:** The country from which the customer belongs to.\n",
    "- **Gender:** The customer’s gender: Male, Female\n",
    "- **Age:** The customer’s current age, in years, at the time of being customer.\n",
    "- **tenure:** The number of years for which the customer has been with the bank.\n",
    "- **balance:** Bank balance of the customer.\n",
    "- **numofproducts:** the number of bank products the customer is utilising.\n",
    "- **hascrcard:** The number of credit cards given to the customer by the bank.\n",
    "- **isactivemember:** Binary Flag for indicating if the client is active or not with the bank before the moment where the client exits the company (recorded in the variable \"exited\")\n",
    "- **exited:** Binary flag 1 if the customer closed account with bank and 0 if the customer is retained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improt Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn(\"this will not show\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement basic steps to see how is your data looks like\n",
    "2. Check for missing values\n",
    "3. Drop the features that not suitable for modelling\n",
    "4. Implement basic visualization steps such as histogram, countplot, heatmap\n",
    "5. Convert categorical variables to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.860</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.800</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.630</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.820</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2      0.000              1          1               1   \n",
       "1       1  83807.860              1          0               1   \n",
       "2       8 159660.800              3          1               0   \n",
       "3       1      0.000              2          0               0   \n",
       "4       2 125510.820              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0       101348.880       1  \n",
       "1       112542.580       0  \n",
       "2       113931.570       1  \n",
       "3        93826.630       0  \n",
       "4        79084.100       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>5000.500</td>\n",
       "      <td>2886.896</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2500.750</td>\n",
       "      <td>5000.500</td>\n",
       "      <td>7500.250</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerId</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>15690940.569</td>\n",
       "      <td>71936.186</td>\n",
       "      <td>15565701.000</td>\n",
       "      <td>15628528.250</td>\n",
       "      <td>15690738.000</td>\n",
       "      <td>15753233.750</td>\n",
       "      <td>15815690.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditScore</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>650.529</td>\n",
       "      <td>96.653</td>\n",
       "      <td>350.000</td>\n",
       "      <td>584.000</td>\n",
       "      <td>652.000</td>\n",
       "      <td>718.000</td>\n",
       "      <td>850.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>38.922</td>\n",
       "      <td>10.488</td>\n",
       "      <td>18.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>37.000</td>\n",
       "      <td>44.000</td>\n",
       "      <td>92.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>5.013</td>\n",
       "      <td>2.892</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balance</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>76485.889</td>\n",
       "      <td>62397.405</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>97198.540</td>\n",
       "      <td>127644.240</td>\n",
       "      <td>250898.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumOfProducts</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>1.530</td>\n",
       "      <td>0.582</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasCrCard</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsActiveMember</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>100090.240</td>\n",
       "      <td>57510.493</td>\n",
       "      <td>11.580</td>\n",
       "      <td>51002.110</td>\n",
       "      <td>100193.915</td>\n",
       "      <td>149388.247</td>\n",
       "      <td>199992.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exited</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count         mean       std          min          25%  \\\n",
       "RowNumber       10000.000     5000.500  2886.896        1.000     2500.750   \n",
       "CustomerId      10000.000 15690940.569 71936.186 15565701.000 15628528.250   \n",
       "CreditScore     10000.000      650.529    96.653      350.000      584.000   \n",
       "Age             10000.000       38.922    10.488       18.000       32.000   \n",
       "Tenure          10000.000        5.013     2.892        0.000        3.000   \n",
       "Balance         10000.000    76485.889 62397.405        0.000        0.000   \n",
       "NumOfProducts   10000.000        1.530     0.582        1.000        1.000   \n",
       "HasCrCard       10000.000        0.706     0.456        0.000        0.000   \n",
       "IsActiveMember  10000.000        0.515     0.500        0.000        0.000   \n",
       "EstimatedSalary 10000.000   100090.240 57510.493       11.580    51002.110   \n",
       "Exited          10000.000        0.204     0.403        0.000        0.000   \n",
       "\n",
       "                         50%          75%          max  \n",
       "RowNumber           5000.500     7500.250    10000.000  \n",
       "CustomerId      15690738.000 15753233.750 15815690.000  \n",
       "CreditScore          652.000      718.000      850.000  \n",
       "Age                   37.000       44.000       92.000  \n",
       "Tenure                 5.000        7.000       10.000  \n",
       "Balance            97198.540   127644.240   250898.090  \n",
       "NumOfProducts          1.000        2.000        4.000  \n",
       "HasCrCard              1.000        1.000        1.000  \n",
       "IsActiveMember         1.000        1.000        1.000  \n",
       "EstimatedSalary   100193.915   149388.247   199992.480  \n",
       "Exited                 0.000        0.000        1.000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('RowNumber', axis = 1) # This column is not helpfull for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Surname', axis = 1) # This column is not helpful for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('CustomerId', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5014\n",
       "2    2509\n",
       "3    2477\n",
       "Name: Geography, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Geography\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Country (x):\n",
    "    if x == \"France\":\n",
    "        return 1\n",
    "    elif x ==\"Germany\":\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Geography\"] = df.Geography.apply(Country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    10000\n",
       "Name: Geography, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Geography\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"] = df.Gender.apply(lambda x : 0 if x == \"Female\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "9995    1\n",
       "9996    1\n",
       "9997    1\n",
       "9998    1\n",
       "9999    1\n",
       "Name: Gender, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.860</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.800</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.630</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.820</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619          3       1   42       2      0.000              1   \n",
       "1          608          3       1   41       1  83807.860              1   \n",
       "2          502          3       1   42       8 159660.800              3   \n",
       "3          699          3       1   39       1      0.000              2   \n",
       "4          850          3       1   43       2 125510.820              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1       101348.880       1  \n",
       "1          0               1       112542.580       0  \n",
       "2          1               0       113931.570       1  \n",
       "3          0               0        93826.630       0  \n",
       "4          1               1        79084.100       0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CreditScore</th>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geography</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balance</th>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumOfProducts</th>\n",
       "      <td>0.012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasCrCard</th>\n",
       "      <td>-0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsActiveMember</th>\n",
       "      <td>0.026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exited</th>\n",
       "      <td>-0.027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.285</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.012</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CreditScore  Geography  Gender    Age  Tenure  Balance  \\\n",
       "CreditScore            1.000        NaN     NaN -0.004   0.001    0.006   \n",
       "Geography                NaN        NaN     NaN    NaN     NaN      NaN   \n",
       "Gender                   NaN        NaN     NaN    NaN     NaN      NaN   \n",
       "Age                   -0.004        NaN     NaN  1.000  -0.010    0.028   \n",
       "Tenure                 0.001        NaN     NaN -0.010   1.000   -0.012   \n",
       "Balance                0.006        NaN     NaN  0.028  -0.012    1.000   \n",
       "NumOfProducts          0.012        NaN     NaN -0.031   0.013   -0.304   \n",
       "HasCrCard             -0.005        NaN     NaN -0.012   0.023   -0.015   \n",
       "IsActiveMember         0.026        NaN     NaN  0.085  -0.028   -0.010   \n",
       "EstimatedSalary       -0.001        NaN     NaN -0.007   0.008    0.013   \n",
       "Exited                -0.027        NaN     NaN  0.285  -0.014    0.119   \n",
       "\n",
       "                 NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "CreditScore              0.012     -0.005           0.026           -0.001   \n",
       "Geography                  NaN        NaN             NaN              NaN   \n",
       "Gender                     NaN        NaN             NaN              NaN   \n",
       "Age                     -0.031     -0.012           0.085           -0.007   \n",
       "Tenure                   0.013      0.023          -0.028            0.008   \n",
       "Balance                 -0.304     -0.015          -0.010            0.013   \n",
       "NumOfProducts            1.000      0.003           0.010            0.014   \n",
       "HasCrCard                0.003      1.000          -0.012           -0.010   \n",
       "IsActiveMember           0.010     -0.012           1.000           -0.011   \n",
       "EstimatedSalary          0.014     -0.010          -0.011            1.000   \n",
       "Exited                  -0.048     -0.007          -0.156            0.012   \n",
       "\n",
       "                 Exited  \n",
       "CreditScore      -0.027  \n",
       "Geography           NaN  \n",
       "Gender              NaN  \n",
       "Age               0.285  \n",
       "Tenure           -0.014  \n",
       "Balance           0.119  \n",
       "NumOfProducts    -0.048  \n",
       "HasCrCard        -0.007  \n",
       "IsActiveMember   -0.156  \n",
       "EstimatedSalary   0.012  \n",
       "Exited            1.000  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=df[\"Balance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=df[\"CreditScore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=df[\"EstimatedSalary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of Data\n",
    "- Train | Test Split, Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited', axis = 1)\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 10)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 10)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ha9hDt_AoGaE"
   },
   "source": [
    "# Modelling & Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without class_weigth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input,Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(actual, pred):\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    mse = mean_squared_error(actual, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    score = r2_score(actual, pred)\n",
    "    return print(\"r2_score:\", score, \"\\nmae:\", mae, \"\\nmse:\", mse, \"\\nrmse:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(15, activation = 'sigmoid', input_dim = X_train.shape[1])) \n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(5, activation = 'sigmoid'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 15)                165       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                160       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 386\n",
      "Trainable params: 386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(10, 15) dtype=float32, numpy=\n",
       " array([[ 0.19575772,  0.16454306, -0.14943665, -0.28060743, -0.01344272,\n",
       "          0.08694485, -0.24747911,  0.30144343, -0.08441624, -0.4214076 ,\n",
       "         -0.07758772, -0.18723151,  0.2653474 ,  0.02079555,  0.48533222],\n",
       "        [ 0.21446851,  0.17790559, -0.3730223 , -0.22606474, -0.03686371,\n",
       "          0.08417401,  0.17751029,  0.39763162,  0.10467157,  0.26247832,\n",
       "          0.18417671, -0.33919668, -0.23846397,  0.3860291 ,  0.32309535],\n",
       "        [ 0.26947048,  0.40360287, -0.37988997, -0.17586002,  0.13810828,\n",
       "          0.4473773 ,  0.43441013,  0.33481994,  0.4045175 ,  0.30771664,\n",
       "         -0.18220651, -0.4362782 , -0.46288309, -0.13089758, -0.39585102],\n",
       "        [-0.11544052,  0.33261648,  0.4674501 ,  0.00088769, -0.4705396 ,\n",
       "          0.06706783,  0.19516733,  0.12248746,  0.08410248, -0.25491884,\n",
       "         -0.2073654 ,  0.2597774 , -0.48348954, -0.25931138,  0.23717263],\n",
       "        [ 0.39639613,  0.20765272,  0.4309632 ,  0.01044431,  0.47490808,\n",
       "         -0.41053975, -0.20158294,  0.00607026, -0.453372  ,  0.05328146,\n",
       "          0.03006056,  0.38008067,  0.33769253, -0.2636051 , -0.21123126],\n",
       "        [ 0.29394725, -0.3056043 , -0.46926343,  0.02036759,  0.4221892 ,\n",
       "          0.16231242,  0.30155483,  0.4721599 ,  0.07563701,  0.4437206 ,\n",
       "          0.38145217, -0.00173017,  0.22847107,  0.15771022,  0.07757744],\n",
       "        [-0.30283052, -0.2618651 , -0.2852382 ,  0.09124163, -0.22712493,\n",
       "         -0.36959022, -0.01491559,  0.41744223, -0.4848733 ,  0.07882908,\n",
       "          0.17127177, -0.42904508,  0.31672302,  0.19777945, -0.05887786],\n",
       "        [-0.43391615, -0.367421  ,  0.46965995, -0.00100169,  0.03117684,\n",
       "          0.4519668 , -0.05272305, -0.3558535 ,  0.30637774, -0.08697453,\n",
       "         -0.24126273,  0.07586864, -0.18697387,  0.31527212, -0.36638778],\n",
       "        [ 0.397042  , -0.19380179, -0.4440639 ,  0.16594294,  0.09852287,\n",
       "         -0.32164994,  0.3155248 , -0.23173052, -0.31260872,  0.40860215,\n",
       "          0.2948207 ,  0.16119125,  0.10624418,  0.19816056, -0.09100392],\n",
       "        [-0.41960606,  0.26794484,  0.04693416,  0.36629388,  0.4280428 ,\n",
       "          0.01726875, -0.17859352, -0.20582643, -0.12388065,  0.30387166,\n",
       "         -0.14075696, -0.44459558, -0.20190927, -0.16544747, -0.19027838]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(15,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(15, 10) dtype=float32, numpy=\n",
       " array([[ 0.26893517,  0.09491572, -0.32564485, -0.05422676, -0.22173831,\n",
       "          0.02112624,  0.13720539,  0.45206055,  0.26473   ,  0.12622681],\n",
       "        [-0.26086098, -0.06553447,  0.25823644,  0.44098297, -0.33625248,\n",
       "         -0.05487242,  0.3867686 ,  0.01028195, -0.05450544,  0.4042665 ],\n",
       "        [ 0.44360593,  0.13360873,  0.06681332,  0.3693668 ,  0.14150074,\n",
       "          0.2532827 ,  0.04678014,  0.14770028, -0.40158722, -0.04643393],\n",
       "        [ 0.2671133 ,  0.38882348,  0.18758544, -0.17300168, -0.40885606,\n",
       "         -0.03436536,  0.34219155, -0.2814374 , -0.06752941, -0.07565489],\n",
       "        [-0.26403737,  0.46990272,  0.22750047, -0.16907659,  0.21923235,\n",
       "         -0.4373717 ,  0.16996661,  0.30715087,  0.02905771,  0.47338006],\n",
       "        [ 0.23793194,  0.35853866,  0.07970205, -0.3729236 , -0.28773987,\n",
       "          0.24383518, -0.4327675 , -0.18956122,  0.20135519,  0.476261  ],\n",
       "        [ 0.01816967, -0.41929877, -0.33157963, -0.4422207 , -0.38245478,\n",
       "         -0.1738674 ,  0.30210695,  0.48549864, -0.3766422 , -0.17009613],\n",
       "        [-0.40407997,  0.31216714,  0.37893453,  0.4754797 ,  0.40632573,\n",
       "          0.10405019, -0.3695128 , -0.01061743,  0.37581524,  0.22168377],\n",
       "        [ 0.05555919,  0.38483503, -0.06285354, -0.25564885, -0.38452005,\n",
       "         -0.2704661 , -0.22372884,  0.19339171,  0.21087512, -0.3424725 ],\n",
       "        [ 0.21144721, -0.15942067, -0.41047   , -0.18428183, -0.3948298 ,\n",
       "         -0.1082221 ,  0.30717787, -0.33936185, -0.22209513,  0.08976325],\n",
       "        [-0.32081062, -0.04008311, -0.47663498,  0.18367913, -0.07785812,\n",
       "         -0.17448518, -0.11032453,  0.42975184,  0.26025245, -0.03916517],\n",
       "        [ 0.36168995,  0.40332076, -0.23985645,  0.17959836,  0.230643  ,\n",
       "          0.02708963, -0.29967153,  0.29663065, -0.408255  , -0.0955728 ],\n",
       "        [-0.43929458,  0.08363649, -0.45192027,  0.43039528,  0.28944352,\n",
       "         -0.02895829,  0.24588266, -0.15410051,  0.01164958, -0.2426154 ],\n",
       "        [ 0.20532629,  0.0696933 , -0.37717795, -0.31450862, -0.07939789,\n",
       "          0.3467599 ,  0.00282004, -0.3843048 , -0.21856987,  0.43650886],\n",
       "        [ 0.02090791, -0.21937811,  0.3754708 ,  0.00567967,  0.4373912 ,\n",
       "          0.42805204,  0.10621724,  0.00554067,  0.22730479, -0.4602011 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(10, 5) dtype=float32, numpy=\n",
       " array([[-0.30730933, -0.1356279 , -0.25668594,  0.34130085,  0.09738624],\n",
       "        [ 0.4296394 , -0.16285998,  0.45639974,  0.28089815,  0.17514539],\n",
       "        [ 0.19687545,  0.61657995, -0.17389503, -0.54756784,  0.51881224],\n",
       "        [-0.26172745,  0.6001429 ,  0.28007364, -0.32139668,  0.04994392],\n",
       "        [ 0.10911888,  0.23974663, -0.44715917, -0.23432165, -0.37723917],\n",
       "        [ 0.5793429 ,  0.17103016,  0.43096477, -0.25218096,  0.05440384],\n",
       "        [ 0.26252013,  0.1742118 , -0.120574  ,  0.5037282 , -0.32308084],\n",
       "        [ 0.57603234,  0.5930281 ,  0.45056933, -0.08924395,  0.32135642],\n",
       "        [ 0.446518  ,  0.38935012,  0.52771395, -0.46853417,  0.07969868],\n",
       "        [ 0.3169508 , -0.1356448 , -0.3086883 , -0.35250312,  0.3003726 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(5,) dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(5, 1) dtype=float32, numpy=\n",
       " array([[ 0.50581694],\n",
       "        [-0.76388264],\n",
       "        [ 0.26101995],\n",
       "        [ 0.8786628 ],\n",
       "        [-0.3003118 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "109/109 [==============================] - 1s 4ms/step - loss: 0.5114 - accuracy: 0.7943 - val_loss: 0.4757 - val_accuracy: 0.8181\n",
      "Epoch 2/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7943 - val_loss: 0.4742 - val_accuracy: 0.8181\n",
      "Epoch 3/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7943 - val_loss: 0.4691 - val_accuracy: 0.8181\n",
      "Epoch 4/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7943 - val_loss: 0.4681 - val_accuracy: 0.8181\n",
      "Epoch 5/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7943 - val_loss: 0.4625 - val_accuracy: 0.8181\n",
      "Epoch 6/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.7943 - val_loss: 0.4590 - val_accuracy: 0.8181\n",
      "Epoch 7/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7943 - val_loss: 0.4613 - val_accuracy: 0.8181\n",
      "Epoch 8/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.7943 - val_loss: 0.4569 - val_accuracy: 0.8181\n",
      "Epoch 9/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7943 - val_loss: 0.4481 - val_accuracy: 0.8181\n",
      "Epoch 10/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7943 - val_loss: 0.4460 - val_accuracy: 0.8181\n",
      "Epoch 11/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7943 - val_loss: 0.4466 - val_accuracy: 0.8181\n",
      "Epoch 12/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7943 - val_loss: 0.4403 - val_accuracy: 0.8181\n",
      "Epoch 13/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7943 - val_loss: 0.4377 - val_accuracy: 0.8181\n",
      "Epoch 14/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7943 - val_loss: 0.4351 - val_accuracy: 0.8181\n",
      "Epoch 15/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7943 - val_loss: 0.4344 - val_accuracy: 0.8181\n",
      "Epoch 16/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7943 - val_loss: 0.4338 - val_accuracy: 0.8181\n",
      "Epoch 17/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7943 - val_loss: 0.4398 - val_accuracy: 0.8181\n",
      "Epoch 18/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7943 - val_loss: 0.4277 - val_accuracy: 0.8181\n",
      "Epoch 19/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7943 - val_loss: 0.4299 - val_accuracy: 0.8181\n",
      "Epoch 20/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7943 - val_loss: 0.4294 - val_accuracy: 0.8181\n",
      "Epoch 21/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7943 - val_loss: 0.4348 - val_accuracy: 0.8181\n",
      "Epoch 22/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7946 - val_loss: 0.4305 - val_accuracy: 0.8181\n",
      "Epoch 23/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7945 - val_loss: 0.4335 - val_accuracy: 0.8181\n",
      "Epoch 24/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7945 - val_loss: 0.4248 - val_accuracy: 0.8181\n",
      "Epoch 25/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7941 - val_loss: 0.4368 - val_accuracy: 0.8171\n",
      "Epoch 26/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7945 - val_loss: 0.4210 - val_accuracy: 0.8181\n",
      "Epoch 27/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7946 - val_loss: 0.4430 - val_accuracy: 0.8190\n",
      "Epoch 28/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7945 - val_loss: 0.4259 - val_accuracy: 0.8171\n",
      "Epoch 29/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7943 - val_loss: 0.4197 - val_accuracy: 0.8181\n",
      "Epoch 30/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7939 - val_loss: 0.4240 - val_accuracy: 0.8171\n",
      "Epoch 31/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7948 - val_loss: 0.4153 - val_accuracy: 0.8181\n",
      "Epoch 32/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7939 - val_loss: 0.4146 - val_accuracy: 0.8171\n",
      "Epoch 33/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7943 - val_loss: 0.4268 - val_accuracy: 0.8181\n",
      "Epoch 34/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7950 - val_loss: 0.4158 - val_accuracy: 0.8171\n",
      "Epoch 35/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7948 - val_loss: 0.4141 - val_accuracy: 0.8171\n",
      "Epoch 36/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7960 - val_loss: 0.4166 - val_accuracy: 0.8181\n",
      "Epoch 37/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7966 - val_loss: 0.4121 - val_accuracy: 0.8171\n",
      "Epoch 38/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7956 - val_loss: 0.4215 - val_accuracy: 0.8171\n",
      "Epoch 39/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7963 - val_loss: 0.4140 - val_accuracy: 0.8181\n",
      "Epoch 40/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7965 - val_loss: 0.4141 - val_accuracy: 0.8181\n",
      "Epoch 41/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7975 - val_loss: 0.4120 - val_accuracy: 0.8171\n",
      "Epoch 42/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7971 - val_loss: 0.4281 - val_accuracy: 0.8190\n",
      "Epoch 43/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7975 - val_loss: 0.4118 - val_accuracy: 0.8181\n",
      "Epoch 44/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7961 - val_loss: 0.4187 - val_accuracy: 0.8171\n",
      "Epoch 45/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7956 - val_loss: 0.4107 - val_accuracy: 0.8171\n",
      "Epoch 46/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7966 - val_loss: 0.4316 - val_accuracy: 0.8200\n",
      "Epoch 47/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7971 - val_loss: 0.4138 - val_accuracy: 0.8171\n",
      "Epoch 48/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7951 - val_loss: 0.4125 - val_accuracy: 0.8171\n",
      "Epoch 49/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7970 - val_loss: 0.4188 - val_accuracy: 0.8171\n",
      "Epoch 50/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7966 - val_loss: 0.4266 - val_accuracy: 0.8190\n",
      "Epoch 51/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7955 - val_loss: 0.4090 - val_accuracy: 0.8171\n",
      "Epoch 52/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7968 - val_loss: 0.4198 - val_accuracy: 0.8200\n",
      "Epoch 53/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7955 - val_loss: 0.4105 - val_accuracy: 0.8162\n",
      "Epoch 54/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7970 - val_loss: 0.4106 - val_accuracy: 0.8162\n",
      "Epoch 55/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7963 - val_loss: 0.4098 - val_accuracy: 0.8171\n",
      "Epoch 56/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7968 - val_loss: 0.4086 - val_accuracy: 0.8171\n",
      "Epoch 57/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7975 - val_loss: 0.4128 - val_accuracy: 0.8152\n",
      "Epoch 58/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7970 - val_loss: 0.4161 - val_accuracy: 0.8190\n",
      "Epoch 59/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7971 - val_loss: 0.4149 - val_accuracy: 0.8152\n",
      "Epoch 60/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7951 - val_loss: 0.4090 - val_accuracy: 0.8162\n",
      "Epoch 61/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7960 - val_loss: 0.4091 - val_accuracy: 0.8162\n",
      "Epoch 62/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7987 - val_loss: 0.4149 - val_accuracy: 0.8190\n",
      "Epoch 63/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7973 - val_loss: 0.4133 - val_accuracy: 0.8190\n",
      "Epoch 64/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7971 - val_loss: 0.4133 - val_accuracy: 0.8171\n",
      "Epoch 65/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7966 - val_loss: 0.4099 - val_accuracy: 0.8171\n",
      "Epoch 66/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7965 - val_loss: 0.4268 - val_accuracy: 0.8152\n",
      "Epoch 67/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7971 - val_loss: 0.4132 - val_accuracy: 0.8190\n",
      "Epoch 68/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7987 - val_loss: 0.4209 - val_accuracy: 0.8190\n",
      "Epoch 69/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7963 - val_loss: 0.4152 - val_accuracy: 0.8190\n",
      "Epoch 70/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7973 - val_loss: 0.4121 - val_accuracy: 0.8181\n",
      "Epoch 71/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7970 - val_loss: 0.4139 - val_accuracy: 0.8200\n",
      "Epoch 72/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7976 - val_loss: 0.4177 - val_accuracy: 0.8190\n",
      "Epoch 73/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7982 - val_loss: 0.4176 - val_accuracy: 0.8171\n",
      "Epoch 74/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7971 - val_loss: 0.4138 - val_accuracy: 0.8181\n",
      "Epoch 75/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7997 - val_loss: 0.4141 - val_accuracy: 0.8181\n",
      "Epoch 76/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7988 - val_loss: 0.4138 - val_accuracy: 0.8162\n",
      "Epoch 77/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7975 - val_loss: 0.4112 - val_accuracy: 0.8190\n",
      "Epoch 78/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7997 - val_loss: 0.4066 - val_accuracy: 0.8171\n",
      "Epoch 79/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.8005 - val_loss: 0.4221 - val_accuracy: 0.8171\n",
      "Epoch 80/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8008 - val_loss: 0.4066 - val_accuracy: 0.8162\n",
      "Epoch 81/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7987 - val_loss: 0.4189 - val_accuracy: 0.8152\n",
      "Epoch 82/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.8000 - val_loss: 0.4101 - val_accuracy: 0.8171\n",
      "Epoch 83/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7976 - val_loss: 0.4114 - val_accuracy: 0.8190\n",
      "Epoch 84/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7983 - val_loss: 0.4068 - val_accuracy: 0.8152\n",
      "Epoch 85/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7988 - val_loss: 0.4056 - val_accuracy: 0.8181\n",
      "Epoch 86/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7990 - val_loss: 0.4141 - val_accuracy: 0.8152\n",
      "Epoch 87/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7990 - val_loss: 0.4065 - val_accuracy: 0.8181\n",
      "Epoch 88/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7983 - val_loss: 0.4137 - val_accuracy: 0.8152\n",
      "Epoch 89/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8008 - val_loss: 0.4057 - val_accuracy: 0.8162\n",
      "Epoch 90/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7993 - val_loss: 0.4067 - val_accuracy: 0.8200\n",
      "Epoch 91/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7998 - val_loss: 0.4214 - val_accuracy: 0.8181\n",
      "Epoch 92/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7992 - val_loss: 0.4054 - val_accuracy: 0.8171\n",
      "Epoch 93/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8007 - val_loss: 0.4065 - val_accuracy: 0.8171\n",
      "Epoch 94/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7985 - val_loss: 0.4315 - val_accuracy: 0.8162\n",
      "Epoch 95/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7998 - val_loss: 0.4179 - val_accuracy: 0.8162\n",
      "Epoch 96/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7997 - val_loss: 0.4104 - val_accuracy: 0.8210\n",
      "Epoch 97/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7982 - val_loss: 0.4137 - val_accuracy: 0.8200\n",
      "Epoch 98/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7993 - val_loss: 0.4083 - val_accuracy: 0.8210\n",
      "Epoch 99/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.8000 - val_loss: 0.4115 - val_accuracy: 0.8171\n",
      "Epoch 100/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.8008 - val_loss: 0.4165 - val_accuracy: 0.8152\n",
      "Epoch 101/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.8002 - val_loss: 0.4230 - val_accuracy: 0.8210\n",
      "Epoch 102/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7990 - val_loss: 0.4186 - val_accuracy: 0.8200\n",
      "Epoch 103/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7993 - val_loss: 0.4076 - val_accuracy: 0.8200\n",
      "Epoch 104/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.8005 - val_loss: 0.4138 - val_accuracy: 0.8152\n",
      "Epoch 105/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.8024 - val_loss: 0.4108 - val_accuracy: 0.8171\n",
      "Epoch 106/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8015 - val_loss: 0.4150 - val_accuracy: 0.8152\n",
      "Epoch 107/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7998 - val_loss: 0.4052 - val_accuracy: 0.8152\n",
      "Epoch 108/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.8005 - val_loss: 0.4315 - val_accuracy: 0.8152\n",
      "Epoch 109/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7998 - val_loss: 0.4095 - val_accuracy: 0.8181\n",
      "Epoch 110/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8010 - val_loss: 0.4063 - val_accuracy: 0.8200\n",
      "Epoch 111/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.8020 - val_loss: 0.4127 - val_accuracy: 0.8162\n",
      "Epoch 112/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8012 - val_loss: 0.4118 - val_accuracy: 0.8171\n",
      "Epoch 113/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.8013 - val_loss: 0.4226 - val_accuracy: 0.8200\n",
      "Epoch 114/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.8025 - val_loss: 0.4056 - val_accuracy: 0.8152\n",
      "Epoch 115/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.8012 - val_loss: 0.4258 - val_accuracy: 0.8200\n",
      "Epoch 116/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.8010 - val_loss: 0.4047 - val_accuracy: 0.8181\n",
      "Epoch 117/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.8030 - val_loss: 0.4095 - val_accuracy: 0.8190\n",
      "Epoch 118/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8044 - val_loss: 0.4157 - val_accuracy: 0.8200\n",
      "Epoch 119/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8044 - val_loss: 0.4040 - val_accuracy: 0.8171\n",
      "Epoch 120/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8029 - val_loss: 0.4046 - val_accuracy: 0.8210\n",
      "Epoch 121/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.8044 - val_loss: 0.4033 - val_accuracy: 0.8181\n",
      "Epoch 122/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.8032 - val_loss: 0.4095 - val_accuracy: 0.8210\n",
      "Epoch 123/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8044 - val_loss: 0.4056 - val_accuracy: 0.8190\n",
      "Epoch 124/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8052 - val_loss: 0.4046 - val_accuracy: 0.8210\n",
      "Epoch 125/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.8066 - val_loss: 0.4055 - val_accuracy: 0.8171\n",
      "Epoch 126/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.8040 - val_loss: 0.4151 - val_accuracy: 0.8219\n",
      "Epoch 127/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8040 - val_loss: 0.4212 - val_accuracy: 0.8229\n",
      "Epoch 128/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8042 - val_loss: 0.4024 - val_accuracy: 0.8190\n",
      "Epoch 129/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8062 - val_loss: 0.4149 - val_accuracy: 0.8229\n",
      "Epoch 130/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8055 - val_loss: 0.4060 - val_accuracy: 0.8200\n",
      "Epoch 131/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.8054 - val_loss: 0.4046 - val_accuracy: 0.8219\n",
      "Epoch 132/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.8059 - val_loss: 0.4018 - val_accuracy: 0.8219\n",
      "Epoch 133/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8077 - val_loss: 0.4107 - val_accuracy: 0.8219\n",
      "Epoch 134/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8050 - val_loss: 0.4018 - val_accuracy: 0.8190\n",
      "Epoch 135/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8059 - val_loss: 0.4029 - val_accuracy: 0.8210\n",
      "Epoch 136/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8057 - val_loss: 0.4100 - val_accuracy: 0.8219\n",
      "Epoch 137/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8050 - val_loss: 0.4147 - val_accuracy: 0.8257\n",
      "Epoch 138/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8062 - val_loss: 0.4077 - val_accuracy: 0.8219\n",
      "Epoch 139/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.8064 - val_loss: 0.4056 - val_accuracy: 0.8229\n",
      "Epoch 140/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8067 - val_loss: 0.4025 - val_accuracy: 0.8248\n",
      "Epoch 141/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8091 - val_loss: 0.4066 - val_accuracy: 0.8219\n",
      "Epoch 142/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8069 - val_loss: 0.4011 - val_accuracy: 0.8200\n",
      "Epoch 143/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.8074 - val_loss: 0.4039 - val_accuracy: 0.8238\n",
      "Epoch 144/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8091 - val_loss: 0.3994 - val_accuracy: 0.8219\n",
      "Epoch 145/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8087 - val_loss: 0.4002 - val_accuracy: 0.8267\n",
      "Epoch 146/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8077 - val_loss: 0.3982 - val_accuracy: 0.8181\n",
      "Epoch 147/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8079 - val_loss: 0.3963 - val_accuracy: 0.8190\n",
      "Epoch 148/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8079 - val_loss: 0.4038 - val_accuracy: 0.8257\n",
      "Epoch 149/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8094 - val_loss: 0.4080 - val_accuracy: 0.8276\n",
      "Epoch 150/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8087 - val_loss: 0.3975 - val_accuracy: 0.8229\n",
      "Epoch 151/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.8092 - val_loss: 0.4015 - val_accuracy: 0.8238\n",
      "Epoch 152/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8087 - val_loss: 0.3961 - val_accuracy: 0.8181\n",
      "Epoch 153/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.8097 - val_loss: 0.4002 - val_accuracy: 0.8248\n",
      "Epoch 154/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8108 - val_loss: 0.3982 - val_accuracy: 0.8238\n",
      "Epoch 155/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8103 - val_loss: 0.4020 - val_accuracy: 0.8276\n",
      "Epoch 156/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8128 - val_loss: 0.4019 - val_accuracy: 0.8276\n",
      "Epoch 157/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8104 - val_loss: 0.4048 - val_accuracy: 0.8295\n",
      "Epoch 158/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8103 - val_loss: 0.3943 - val_accuracy: 0.8248\n",
      "Epoch 159/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8126 - val_loss: 0.3970 - val_accuracy: 0.8248\n",
      "Epoch 160/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8116 - val_loss: 0.4088 - val_accuracy: 0.8181\n",
      "Epoch 161/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8101 - val_loss: 0.3927 - val_accuracy: 0.8248\n",
      "Epoch 162/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8101 - val_loss: 0.4139 - val_accuracy: 0.8295\n",
      "Epoch 163/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8114 - val_loss: 0.3939 - val_accuracy: 0.8190\n",
      "Epoch 164/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8097 - val_loss: 0.4014 - val_accuracy: 0.8295\n",
      "Epoch 165/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8113 - val_loss: 0.3909 - val_accuracy: 0.8248\n",
      "Epoch 166/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8099 - val_loss: 0.3956 - val_accuracy: 0.8267\n",
      "Epoch 167/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8124 - val_loss: 0.4208 - val_accuracy: 0.8314\n",
      "Epoch 168/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.8118 - val_loss: 0.3943 - val_accuracy: 0.8276\n",
      "Epoch 169/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8116 - val_loss: 0.3898 - val_accuracy: 0.8248\n",
      "Epoch 170/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8121 - val_loss: 0.3906 - val_accuracy: 0.8267\n",
      "Epoch 171/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8114 - val_loss: 0.3915 - val_accuracy: 0.8276\n",
      "Epoch 172/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8106 - val_loss: 0.4065 - val_accuracy: 0.8324\n",
      "Epoch 173/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8092 - val_loss: 0.3894 - val_accuracy: 0.8200\n",
      "Epoch 174/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8104 - val_loss: 0.3935 - val_accuracy: 0.8295\n",
      "Epoch 175/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8121 - val_loss: 0.3893 - val_accuracy: 0.8267\n",
      "Epoch 176/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.8114 - val_loss: 0.3878 - val_accuracy: 0.8257\n",
      "Epoch 177/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.8131 - val_loss: 0.4010 - val_accuracy: 0.8324\n",
      "Epoch 178/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.8104 - val_loss: 0.3901 - val_accuracy: 0.8295\n",
      "Epoch 179/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.8131 - val_loss: 0.3853 - val_accuracy: 0.8286\n",
      "Epoch 180/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8165 - val_loss: 0.3986 - val_accuracy: 0.8352\n",
      "Epoch 181/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.8124 - val_loss: 0.3908 - val_accuracy: 0.8305\n",
      "Epoch 182/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8131 - val_loss: 0.3883 - val_accuracy: 0.8314\n",
      "Epoch 183/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8126 - val_loss: 0.3884 - val_accuracy: 0.8314\n",
      "Epoch 184/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8139 - val_loss: 0.3924 - val_accuracy: 0.8305\n",
      "Epoch 185/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8134 - val_loss: 0.3964 - val_accuracy: 0.8324\n",
      "Epoch 186/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8153 - val_loss: 0.3874 - val_accuracy: 0.8314\n",
      "Epoch 187/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8143 - val_loss: 0.3848 - val_accuracy: 0.8314\n",
      "Epoch 188/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8139 - val_loss: 0.3839 - val_accuracy: 0.8314\n",
      "Epoch 189/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8151 - val_loss: 0.3890 - val_accuracy: 0.8314\n",
      "Epoch 190/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8150 - val_loss: 0.3914 - val_accuracy: 0.8314\n",
      "Epoch 191/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8148 - val_loss: 0.3826 - val_accuracy: 0.8295\n",
      "Epoch 192/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8145 - val_loss: 0.3818 - val_accuracy: 0.8314\n",
      "Epoch 193/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8129 - val_loss: 0.3860 - val_accuracy: 0.8314\n",
      "Epoch 194/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8128 - val_loss: 0.3815 - val_accuracy: 0.8352\n",
      "Epoch 195/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8155 - val_loss: 0.3811 - val_accuracy: 0.8295\n",
      "Epoch 196/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8146 - val_loss: 0.3852 - val_accuracy: 0.8352\n",
      "Epoch 197/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8156 - val_loss: 0.3926 - val_accuracy: 0.8362\n",
      "Epoch 198/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8176 - val_loss: 0.3908 - val_accuracy: 0.8371\n",
      "Epoch 199/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8175 - val_loss: 0.3809 - val_accuracy: 0.8314\n",
      "Epoch 200/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8165 - val_loss: 0.3797 - val_accuracy: 0.8314\n",
      "Epoch 201/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8173 - val_loss: 0.3780 - val_accuracy: 0.8324\n",
      "Epoch 202/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8198 - val_loss: 0.3921 - val_accuracy: 0.8305\n",
      "Epoch 203/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8173 - val_loss: 0.3813 - val_accuracy: 0.8314\n",
      "Epoch 204/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8185 - val_loss: 0.3884 - val_accuracy: 0.8371\n",
      "Epoch 205/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8193 - val_loss: 0.3842 - val_accuracy: 0.8333\n",
      "Epoch 206/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8168 - val_loss: 0.3787 - val_accuracy: 0.8305\n",
      "Epoch 207/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8192 - val_loss: 0.3770 - val_accuracy: 0.8333\n",
      "Epoch 208/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8183 - val_loss: 0.3845 - val_accuracy: 0.8381\n",
      "Epoch 209/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8182 - val_loss: 0.3747 - val_accuracy: 0.8352\n",
      "Epoch 210/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8195 - val_loss: 0.3800 - val_accuracy: 0.8295\n",
      "Epoch 211/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8185 - val_loss: 0.3816 - val_accuracy: 0.8314\n",
      "Epoch 212/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8203 - val_loss: 0.3767 - val_accuracy: 0.8352\n",
      "Epoch 213/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8203 - val_loss: 0.3750 - val_accuracy: 0.8333\n",
      "Epoch 214/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8217 - val_loss: 0.3745 - val_accuracy: 0.8352\n",
      "Epoch 215/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8178 - val_loss: 0.3769 - val_accuracy: 0.8352\n",
      "Epoch 216/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8239 - val_loss: 0.3745 - val_accuracy: 0.8333\n",
      "Epoch 217/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8234 - val_loss: 0.3765 - val_accuracy: 0.8362\n",
      "Epoch 218/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8239 - val_loss: 0.3727 - val_accuracy: 0.8371\n",
      "Epoch 219/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8212 - val_loss: 0.3813 - val_accuracy: 0.8419\n",
      "Epoch 220/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8235 - val_loss: 0.3912 - val_accuracy: 0.8286\n",
      "Epoch 221/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8227 - val_loss: 0.3747 - val_accuracy: 0.8381\n",
      "Epoch 222/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8229 - val_loss: 0.3729 - val_accuracy: 0.8390\n",
      "Epoch 223/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8245 - val_loss: 0.3722 - val_accuracy: 0.8362\n",
      "Epoch 224/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8234 - val_loss: 0.3784 - val_accuracy: 0.8390\n",
      "Epoch 225/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8234 - val_loss: 0.3772 - val_accuracy: 0.8371\n",
      "Epoch 226/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8252 - val_loss: 0.3755 - val_accuracy: 0.8400\n",
      "Epoch 227/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8266 - val_loss: 0.3701 - val_accuracy: 0.8381\n",
      "Epoch 228/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8247 - val_loss: 0.3790 - val_accuracy: 0.8410\n",
      "Epoch 229/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8242 - val_loss: 0.3710 - val_accuracy: 0.8400\n",
      "Epoch 230/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8262 - val_loss: 0.3746 - val_accuracy: 0.8400\n",
      "Epoch 231/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8277 - val_loss: 0.3758 - val_accuracy: 0.8419\n",
      "Epoch 232/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8262 - val_loss: 0.3681 - val_accuracy: 0.8362\n",
      "Epoch 233/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8264 - val_loss: 0.3677 - val_accuracy: 0.8390\n",
      "Epoch 234/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8291 - val_loss: 0.3690 - val_accuracy: 0.8410\n",
      "Epoch 235/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8282 - val_loss: 0.3709 - val_accuracy: 0.8352\n",
      "Epoch 236/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8284 - val_loss: 0.3691 - val_accuracy: 0.8410\n",
      "Epoch 237/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8262 - val_loss: 0.3703 - val_accuracy: 0.8400\n",
      "Epoch 238/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8269 - val_loss: 0.3662 - val_accuracy: 0.8419\n",
      "Epoch 239/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8296 - val_loss: 0.3661 - val_accuracy: 0.8410\n",
      "Epoch 240/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8287 - val_loss: 0.3705 - val_accuracy: 0.8419\n",
      "Epoch 241/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8296 - val_loss: 0.3704 - val_accuracy: 0.8419\n",
      "Epoch 242/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8277 - val_loss: 0.3680 - val_accuracy: 0.8429\n",
      "Epoch 243/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8272 - val_loss: 0.3708 - val_accuracy: 0.8381\n",
      "Epoch 244/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8313 - val_loss: 0.3655 - val_accuracy: 0.8419\n",
      "Epoch 245/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8297 - val_loss: 0.3667 - val_accuracy: 0.8429\n",
      "Epoch 246/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8316 - val_loss: 0.3695 - val_accuracy: 0.8505\n",
      "Epoch 247/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8318 - val_loss: 0.3760 - val_accuracy: 0.8410\n",
      "Epoch 248/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8331 - val_loss: 0.3645 - val_accuracy: 0.8457\n",
      "Epoch 249/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8318 - val_loss: 0.3817 - val_accuracy: 0.8486\n",
      "Epoch 250/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8316 - val_loss: 0.3675 - val_accuracy: 0.8438\n",
      "Epoch 251/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8339 - val_loss: 0.3768 - val_accuracy: 0.8410\n",
      "Epoch 252/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8316 - val_loss: 0.3647 - val_accuracy: 0.8448\n",
      "Epoch 253/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8346 - val_loss: 0.3754 - val_accuracy: 0.8419\n",
      "Epoch 254/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8353 - val_loss: 0.3749 - val_accuracy: 0.8505\n",
      "Epoch 255/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8321 - val_loss: 0.3681 - val_accuracy: 0.8524\n",
      "Epoch 256/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8345 - val_loss: 0.3631 - val_accuracy: 0.8476\n",
      "Epoch 257/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8343 - val_loss: 0.3726 - val_accuracy: 0.8486\n",
      "Epoch 258/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8380 - val_loss: 0.3853 - val_accuracy: 0.8448\n",
      "Epoch 259/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8383 - val_loss: 0.3622 - val_accuracy: 0.8495\n",
      "Epoch 260/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8368 - val_loss: 0.3637 - val_accuracy: 0.8486\n",
      "Epoch 261/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8371 - val_loss: 0.3637 - val_accuracy: 0.8457\n",
      "Epoch 262/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8366 - val_loss: 0.3994 - val_accuracy: 0.8419\n",
      "Epoch 263/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8346 - val_loss: 0.3635 - val_accuracy: 0.8486\n",
      "Epoch 264/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8370 - val_loss: 0.3702 - val_accuracy: 0.8486\n",
      "Epoch 265/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8363 - val_loss: 0.3955 - val_accuracy: 0.8429\n",
      "Epoch 266/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8376 - val_loss: 0.3705 - val_accuracy: 0.8533\n",
      "Epoch 267/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8427 - val_loss: 0.3701 - val_accuracy: 0.8486\n",
      "Epoch 268/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8408 - val_loss: 0.3624 - val_accuracy: 0.8533\n",
      "Epoch 269/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8420 - val_loss: 0.3804 - val_accuracy: 0.8476\n",
      "Epoch 270/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8397 - val_loss: 0.3808 - val_accuracy: 0.8476\n",
      "Epoch 271/600\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8388 - val_loss: 0.3694 - val_accuracy: 0.8476\n",
      "Epoch 272/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8415 - val_loss: 0.3708 - val_accuracy: 0.8476\n",
      "Epoch 273/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8395 - val_loss: 0.3717 - val_accuracy: 0.8467\n",
      "Epoch 274/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8434 - val_loss: 0.3637 - val_accuracy: 0.8533\n",
      "Epoch 275/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8424 - val_loss: 0.3692 - val_accuracy: 0.8514\n",
      "Epoch 276/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8417 - val_loss: 0.3905 - val_accuracy: 0.8476\n",
      "Epoch 277/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.8407 - val_loss: 0.4153 - val_accuracy: 0.8438\n",
      "Epoch 278/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8402 - val_loss: 0.3697 - val_accuracy: 0.8505\n",
      "Epoch 279/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8425 - val_loss: 0.3696 - val_accuracy: 0.8467\n",
      "Epoch 280/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.8434 - val_loss: 0.3641 - val_accuracy: 0.8524\n",
      "Epoch 281/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8418 - val_loss: 0.3688 - val_accuracy: 0.8476\n",
      "Epoch 282/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8403 - val_loss: 0.3692 - val_accuracy: 0.8514\n",
      "Epoch 283/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8435 - val_loss: 0.3652 - val_accuracy: 0.8495\n",
      "Epoch 284/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8432 - val_loss: 0.4196 - val_accuracy: 0.8448\n",
      "Epoch 285/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8425 - val_loss: 0.3825 - val_accuracy: 0.8495\n",
      "Epoch 286/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.8429 - val_loss: 0.3675 - val_accuracy: 0.8552\n",
      "Epoch 287/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8450 - val_loss: 0.4147 - val_accuracy: 0.8457\n",
      "Epoch 288/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8444 - val_loss: 0.3726 - val_accuracy: 0.8486\n",
      "Epoch 289/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8447 - val_loss: 0.3675 - val_accuracy: 0.8476\n",
      "Epoch 290/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8432 - val_loss: 0.4173 - val_accuracy: 0.8448\n",
      "Epoch 291/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8444 - val_loss: 0.3691 - val_accuracy: 0.8486\n",
      "Epoch 292/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8440 - val_loss: 0.3895 - val_accuracy: 0.8495\n",
      "Epoch 293/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8457 - val_loss: 0.3609 - val_accuracy: 0.8543\n",
      "Epoch 294/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8444 - val_loss: 0.3906 - val_accuracy: 0.8457\n",
      "Epoch 295/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8457 - val_loss: 0.3665 - val_accuracy: 0.8514\n",
      "Epoch 296/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8455 - val_loss: 0.3871 - val_accuracy: 0.8486\n",
      "Epoch 297/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8417 - val_loss: 0.3824 - val_accuracy: 0.8486\n",
      "Epoch 298/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8366 - val_loss: 0.3941 - val_accuracy: 0.8495\n",
      "Epoch 299/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8413 - val_loss: 0.3732 - val_accuracy: 0.8524\n",
      "Epoch 300/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8457 - val_loss: 0.3920 - val_accuracy: 0.8505\n",
      "Epoch 301/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8429 - val_loss: 0.3711 - val_accuracy: 0.8505\n",
      "Epoch 302/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8407 - val_loss: 0.3599 - val_accuracy: 0.8505\n",
      "Epoch 303/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8439 - val_loss: 0.3642 - val_accuracy: 0.8533\n",
      "Epoch 304/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8432 - val_loss: 0.3751 - val_accuracy: 0.8524\n",
      "Epoch 305/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4036 - accuracy: 0.8442 - val_loss: 0.3694 - val_accuracy: 0.8514\n",
      "Epoch 306/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8442 - val_loss: 0.3686 - val_accuracy: 0.8486\n",
      "Epoch 307/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8447 - val_loss: 0.3598 - val_accuracy: 0.8533\n",
      "Epoch 308/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8434 - val_loss: 0.3594 - val_accuracy: 0.8505\n",
      "Epoch 309/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8457 - val_loss: 0.3886 - val_accuracy: 0.8495\n",
      "Epoch 310/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8459 - val_loss: 0.3606 - val_accuracy: 0.8524\n",
      "Epoch 311/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8455 - val_loss: 0.3677 - val_accuracy: 0.8505\n",
      "Epoch 312/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8442 - val_loss: 0.3665 - val_accuracy: 0.8495\n",
      "Epoch 313/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8471 - val_loss: 0.3593 - val_accuracy: 0.8505\n",
      "Epoch 314/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8466 - val_loss: 0.3770 - val_accuracy: 0.8505\n",
      "Epoch 315/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8459 - val_loss: 0.3592 - val_accuracy: 0.8543\n",
      "Epoch 316/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8469 - val_loss: 0.4387 - val_accuracy: 0.8457\n",
      "Epoch 317/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8430 - val_loss: 0.3625 - val_accuracy: 0.8562\n",
      "Epoch 318/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8440 - val_loss: 0.3729 - val_accuracy: 0.8552\n",
      "Epoch 319/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8457 - val_loss: 0.3589 - val_accuracy: 0.8495\n",
      "Epoch 320/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8455 - val_loss: 0.3938 - val_accuracy: 0.8514\n",
      "Epoch 321/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8450 - val_loss: 0.3570 - val_accuracy: 0.8514\n",
      "Epoch 322/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8427 - val_loss: 0.3877 - val_accuracy: 0.8514\n",
      "Epoch 323/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8481 - val_loss: 0.3564 - val_accuracy: 0.8533\n",
      "Epoch 324/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8492 - val_loss: 0.3866 - val_accuracy: 0.8514\n",
      "Epoch 325/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8469 - val_loss: 0.3866 - val_accuracy: 0.8562\n",
      "Epoch 326/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8476 - val_loss: 0.4111 - val_accuracy: 0.8505\n",
      "Epoch 327/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8467 - val_loss: 0.3621 - val_accuracy: 0.8562\n",
      "Epoch 328/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8481 - val_loss: 0.3780 - val_accuracy: 0.8524\n",
      "Epoch 329/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8481 - val_loss: 0.4340 - val_accuracy: 0.8505\n",
      "Epoch 330/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8452 - val_loss: 0.3622 - val_accuracy: 0.8571\n",
      "Epoch 331/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8469 - val_loss: 0.3609 - val_accuracy: 0.8543\n",
      "Epoch 332/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8467 - val_loss: 0.3647 - val_accuracy: 0.8562\n",
      "Epoch 333/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8489 - val_loss: 0.3766 - val_accuracy: 0.8552\n",
      "Epoch 334/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.8445 - val_loss: 0.3761 - val_accuracy: 0.8571\n",
      "Epoch 335/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8484 - val_loss: 0.3733 - val_accuracy: 0.8524\n",
      "Epoch 336/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8479 - val_loss: 0.3580 - val_accuracy: 0.8524\n",
      "Epoch 337/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8482 - val_loss: 0.3810 - val_accuracy: 0.8552\n",
      "Epoch 338/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8482 - val_loss: 0.3572 - val_accuracy: 0.8543\n",
      "Epoch 339/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8482 - val_loss: 0.3560 - val_accuracy: 0.8552\n",
      "Epoch 340/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8469 - val_loss: 0.3551 - val_accuracy: 0.8571\n",
      "Epoch 341/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8484 - val_loss: 0.3883 - val_accuracy: 0.8533\n",
      "Epoch 342/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8508 - val_loss: 0.3959 - val_accuracy: 0.8533\n",
      "Epoch 343/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8504 - val_loss: 0.3634 - val_accuracy: 0.8533\n",
      "Epoch 344/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8469 - val_loss: 0.3843 - val_accuracy: 0.8552\n",
      "Epoch 345/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8471 - val_loss: 0.3674 - val_accuracy: 0.8562\n",
      "Epoch 346/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8477 - val_loss: 0.3561 - val_accuracy: 0.8552\n",
      "Epoch 347/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8471 - val_loss: 0.3558 - val_accuracy: 0.8571\n",
      "Epoch 348/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8491 - val_loss: 0.3544 - val_accuracy: 0.8571\n",
      "Epoch 349/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.8481 - val_loss: 0.3677 - val_accuracy: 0.8552\n",
      "Epoch 350/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8481 - val_loss: 0.3561 - val_accuracy: 0.8543\n",
      "Epoch 351/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8487 - val_loss: 0.3545 - val_accuracy: 0.8562\n",
      "Epoch 352/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.8486 - val_loss: 0.3531 - val_accuracy: 0.8552\n",
      "Epoch 353/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8450 - val_loss: 0.3703 - val_accuracy: 0.8543\n",
      "Epoch 354/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8444 - val_loss: 0.3566 - val_accuracy: 0.8552\n",
      "Epoch 355/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8499 - val_loss: 0.3833 - val_accuracy: 0.8562\n",
      "Epoch 356/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8486 - val_loss: 0.3665 - val_accuracy: 0.8562\n",
      "Epoch 357/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8487 - val_loss: 0.3746 - val_accuracy: 0.8514\n",
      "Epoch 358/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8462 - val_loss: 0.3537 - val_accuracy: 0.8562\n",
      "Epoch 359/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8492 - val_loss: 0.3624 - val_accuracy: 0.8543\n",
      "Epoch 360/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8467 - val_loss: 0.3592 - val_accuracy: 0.8562\n",
      "Epoch 361/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8469 - val_loss: 0.3552 - val_accuracy: 0.8562\n",
      "Epoch 362/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8487 - val_loss: 0.3694 - val_accuracy: 0.8571\n",
      "Epoch 363/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8494 - val_loss: 0.3746 - val_accuracy: 0.8552\n",
      "Epoch 364/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8469 - val_loss: 0.3592 - val_accuracy: 0.8552\n",
      "Epoch 365/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8501 - val_loss: 0.3543 - val_accuracy: 0.8543\n",
      "Epoch 366/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8508 - val_loss: 0.3767 - val_accuracy: 0.8533\n",
      "Epoch 367/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8499 - val_loss: 0.3567 - val_accuracy: 0.8533\n",
      "Epoch 368/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8492 - val_loss: 0.3555 - val_accuracy: 0.8533\n",
      "Epoch 369/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8482 - val_loss: 0.3607 - val_accuracy: 0.8543\n",
      "Epoch 370/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8487 - val_loss: 0.3710 - val_accuracy: 0.8552\n",
      "Epoch 371/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8492 - val_loss: 0.3573 - val_accuracy: 0.8562\n",
      "Epoch 372/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8508 - val_loss: 0.3800 - val_accuracy: 0.8562\n",
      "Epoch 373/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.8503 - val_loss: 0.3848 - val_accuracy: 0.8552\n",
      "Epoch 374/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3965 - accuracy: 0.8486 - val_loss: 0.3969 - val_accuracy: 0.8533\n",
      "Epoch 375/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8514 - val_loss: 0.3551 - val_accuracy: 0.8571\n",
      "Epoch 376/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.8499 - val_loss: 0.3639 - val_accuracy: 0.8543\n",
      "Epoch 377/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8461 - val_loss: 0.3852 - val_accuracy: 0.8543\n",
      "Epoch 378/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8494 - val_loss: 0.3524 - val_accuracy: 0.8581\n",
      "Epoch 379/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8494 - val_loss: 0.3767 - val_accuracy: 0.8600\n",
      "Epoch 380/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8514 - val_loss: 0.3536 - val_accuracy: 0.8562\n",
      "Epoch 381/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8496 - val_loss: 0.3589 - val_accuracy: 0.8533\n",
      "Epoch 382/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8501 - val_loss: 0.3744 - val_accuracy: 0.8552\n",
      "Epoch 383/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.8513 - val_loss: 0.3660 - val_accuracy: 0.8552\n",
      "Epoch 384/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8489 - val_loss: 0.3553 - val_accuracy: 0.8552\n",
      "Epoch 385/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8474 - val_loss: 0.3595 - val_accuracy: 0.8543\n",
      "Epoch 386/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8511 - val_loss: 0.3572 - val_accuracy: 0.8581\n",
      "Epoch 387/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8477 - val_loss: 0.3654 - val_accuracy: 0.8571\n",
      "Epoch 388/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8506 - val_loss: 0.3584 - val_accuracy: 0.8590\n",
      "Epoch 389/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8503 - val_loss: 0.3543 - val_accuracy: 0.8543\n",
      "Epoch 390/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8508 - val_loss: 0.3573 - val_accuracy: 0.8562\n",
      "Epoch 391/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8471 - val_loss: 0.3592 - val_accuracy: 0.8552\n",
      "Epoch 392/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3946 - accuracy: 0.8524 - val_loss: 0.3553 - val_accuracy: 0.8552\n",
      "Epoch 393/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8514 - val_loss: 0.4209 - val_accuracy: 0.8543\n",
      "Epoch 394/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.8479 - val_loss: 0.3598 - val_accuracy: 0.8571\n",
      "Epoch 395/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8509 - val_loss: 0.3541 - val_accuracy: 0.8571\n",
      "Epoch 396/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4034 - accuracy: 0.8533 - val_loss: 0.3582 - val_accuracy: 0.8581\n",
      "Epoch 397/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8518 - val_loss: 0.3988 - val_accuracy: 0.8514\n",
      "Epoch 398/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8513 - val_loss: 0.3837 - val_accuracy: 0.8571\n",
      "Epoch 399/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8496 - val_loss: 0.3739 - val_accuracy: 0.8552\n",
      "Epoch 400/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8511 - val_loss: 0.3723 - val_accuracy: 0.8562\n",
      "Epoch 401/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8514 - val_loss: 0.3564 - val_accuracy: 0.8590\n",
      "Epoch 402/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8523 - val_loss: 0.3840 - val_accuracy: 0.8562\n",
      "Epoch 403/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8521 - val_loss: 0.3733 - val_accuracy: 0.8610\n",
      "Epoch 404/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4034 - accuracy: 0.8503 - val_loss: 0.3619 - val_accuracy: 0.8562\n",
      "Epoch 405/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8503 - val_loss: 0.3576 - val_accuracy: 0.8571\n",
      "Epoch 406/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8511 - val_loss: 0.3532 - val_accuracy: 0.8562\n",
      "Epoch 407/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8494 - val_loss: 0.3558 - val_accuracy: 0.8571\n",
      "Epoch 408/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8513 - val_loss: 0.3597 - val_accuracy: 0.8543\n",
      "Epoch 409/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8497 - val_loss: 0.3630 - val_accuracy: 0.8590\n",
      "Epoch 410/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8514 - val_loss: 0.3965 - val_accuracy: 0.8533\n",
      "Epoch 411/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8494 - val_loss: 0.3646 - val_accuracy: 0.8552\n",
      "Epoch 412/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8516 - val_loss: 0.3539 - val_accuracy: 0.8562\n",
      "Epoch 413/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8497 - val_loss: 0.3538 - val_accuracy: 0.8581\n",
      "Epoch 414/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8511 - val_loss: 0.3668 - val_accuracy: 0.8581\n",
      "Epoch 415/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8519 - val_loss: 0.3574 - val_accuracy: 0.8590\n",
      "Epoch 416/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8513 - val_loss: 0.3546 - val_accuracy: 0.8581\n",
      "Epoch 417/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4017 - accuracy: 0.8519 - val_loss: 0.4182 - val_accuracy: 0.8543\n",
      "Epoch 418/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8524 - val_loss: 0.3575 - val_accuracy: 0.8590\n",
      "Epoch 419/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8513 - val_loss: 0.3992 - val_accuracy: 0.8543\n",
      "Epoch 420/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8514 - val_loss: 0.3746 - val_accuracy: 0.8543\n",
      "Epoch 421/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8524 - val_loss: 0.3542 - val_accuracy: 0.8590\n",
      "Epoch 422/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3914 - accuracy: 0.8503 - val_loss: 0.3729 - val_accuracy: 0.8562\n",
      "Epoch 423/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8524 - val_loss: 0.3639 - val_accuracy: 0.8590\n",
      "Epoch 424/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8519 - val_loss: 0.3828 - val_accuracy: 0.8571\n",
      "Epoch 425/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8511 - val_loss: 0.3834 - val_accuracy: 0.8543\n",
      "Epoch 426/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8519 - val_loss: 0.3533 - val_accuracy: 0.8590\n",
      "Epoch 427/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8524 - val_loss: 0.3653 - val_accuracy: 0.8562\n",
      "Epoch 428/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8531 - val_loss: 0.3549 - val_accuracy: 0.8600\n",
      "Epoch 429/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3937 - accuracy: 0.8526 - val_loss: 0.3714 - val_accuracy: 0.8571\n",
      "Epoch 430/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8523 - val_loss: 0.3563 - val_accuracy: 0.8590\n",
      "Epoch 431/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8541 - val_loss: 0.4061 - val_accuracy: 0.8543\n",
      "Epoch 432/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.8489 - val_loss: 0.3566 - val_accuracy: 0.8600\n",
      "Epoch 433/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8558 - val_loss: 0.3831 - val_accuracy: 0.8571\n",
      "Epoch 434/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8533 - val_loss: 0.3544 - val_accuracy: 0.8600\n",
      "Epoch 435/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8524 - val_loss: 0.3612 - val_accuracy: 0.8571\n",
      "Epoch 436/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8509 - val_loss: 0.3644 - val_accuracy: 0.8571\n",
      "Epoch 437/600\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.3939 - accuracy: 0.8521 - val_loss: 0.3720 - val_accuracy: 0.8562\n",
      "Epoch 438/600\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.4063 - accuracy: 0.8499 - val_loss: 0.3721 - val_accuracy: 0.8562\n",
      "Epoch 439/600\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 0.4015 - accuracy: 0.8545 - val_loss: 0.3718 - val_accuracy: 0.8552\n",
      "Epoch 440/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8523 - val_loss: 0.3982 - val_accuracy: 0.8552\n",
      "Epoch 441/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3905 - accuracy: 0.8509 - val_loss: 0.4023 - val_accuracy: 0.8590\n",
      "Epoch 442/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8531 - val_loss: 0.4109 - val_accuracy: 0.8543\n",
      "Epoch 443/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8519 - val_loss: 0.3707 - val_accuracy: 0.8581\n",
      "Epoch 444/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8519 - val_loss: 0.3718 - val_accuracy: 0.8562\n",
      "Epoch 445/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8526 - val_loss: 0.3713 - val_accuracy: 0.8581\n",
      "Epoch 446/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8534 - val_loss: 0.3636 - val_accuracy: 0.8562\n",
      "Epoch 447/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8533 - val_loss: 0.3541 - val_accuracy: 0.8610\n",
      "Epoch 448/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8529 - val_loss: 0.3839 - val_accuracy: 0.8581\n",
      "Epoch 449/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8538 - val_loss: 0.3709 - val_accuracy: 0.8571\n",
      "Epoch 450/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8531 - val_loss: 0.3719 - val_accuracy: 0.8552\n",
      "Epoch 451/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8508 - val_loss: 0.3641 - val_accuracy: 0.8562\n",
      "Epoch 452/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8514 - val_loss: 0.3767 - val_accuracy: 0.8610\n",
      "Epoch 453/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8514 - val_loss: 0.3573 - val_accuracy: 0.8619\n",
      "Epoch 454/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8528 - val_loss: 0.3684 - val_accuracy: 0.8600\n",
      "Epoch 455/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8536 - val_loss: 0.3898 - val_accuracy: 0.8610\n",
      "Epoch 456/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8529 - val_loss: 0.3726 - val_accuracy: 0.8552\n",
      "Epoch 457/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8526 - val_loss: 0.3684 - val_accuracy: 0.8619\n",
      "Epoch 458/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8528 - val_loss: 0.3703 - val_accuracy: 0.8600\n",
      "Epoch 459/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.8556 - val_loss: 0.3703 - val_accuracy: 0.8600\n",
      "Epoch 460/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8523 - val_loss: 0.3604 - val_accuracy: 0.8619\n",
      "Epoch 461/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3953 - accuracy: 0.8524 - val_loss: 0.3594 - val_accuracy: 0.8600\n",
      "Epoch 462/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8524 - val_loss: 0.3737 - val_accuracy: 0.8552\n",
      "Epoch 463/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8538 - val_loss: 0.3912 - val_accuracy: 0.8600\n",
      "Epoch 464/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8526 - val_loss: 0.3834 - val_accuracy: 0.8638\n",
      "Epoch 465/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8528 - val_loss: 0.4173 - val_accuracy: 0.8571\n",
      "Epoch 466/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8536 - val_loss: 0.3927 - val_accuracy: 0.8571\n",
      "Epoch 467/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8531 - val_loss: 0.3784 - val_accuracy: 0.8552\n",
      "Epoch 468/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.8545 - val_loss: 0.3547 - val_accuracy: 0.8590\n",
      "Epoch 469/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8538 - val_loss: 0.3551 - val_accuracy: 0.8562\n",
      "Epoch 470/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8543 - val_loss: 0.3898 - val_accuracy: 0.8543\n",
      "Epoch 471/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.8536 - val_loss: 0.3715 - val_accuracy: 0.8619\n",
      "Epoch 472/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8533 - val_loss: 0.3726 - val_accuracy: 0.8562\n",
      "Epoch 473/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8546 - val_loss: 0.3747 - val_accuracy: 0.8552\n",
      "Epoch 474/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8534 - val_loss: 0.3620 - val_accuracy: 0.8590\n",
      "Epoch 475/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8531 - val_loss: 0.3585 - val_accuracy: 0.8562\n",
      "Epoch 476/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8523 - val_loss: 0.3534 - val_accuracy: 0.8581\n",
      "Epoch 477/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8513 - val_loss: 0.3833 - val_accuracy: 0.8552\n",
      "Epoch 478/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8531 - val_loss: 0.4196 - val_accuracy: 0.8514\n",
      "Epoch 479/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8529 - val_loss: 0.3674 - val_accuracy: 0.8590\n",
      "Epoch 480/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8528 - val_loss: 0.3836 - val_accuracy: 0.8543\n",
      "Epoch 481/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8524 - val_loss: 0.4486 - val_accuracy: 0.8476\n",
      "Epoch 482/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8501 - val_loss: 0.3694 - val_accuracy: 0.8571\n",
      "Epoch 483/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8516 - val_loss: 0.3645 - val_accuracy: 0.8590\n",
      "Epoch 484/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8528 - val_loss: 0.3725 - val_accuracy: 0.8581\n",
      "Epoch 485/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8543 - val_loss: 0.4023 - val_accuracy: 0.8600\n",
      "Epoch 486/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8523 - val_loss: 0.3527 - val_accuracy: 0.8590\n",
      "Epoch 487/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8531 - val_loss: 0.3661 - val_accuracy: 0.8600\n",
      "Epoch 488/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8539 - val_loss: 0.3707 - val_accuracy: 0.8590\n",
      "Epoch 489/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3960 - accuracy: 0.8536 - val_loss: 0.3936 - val_accuracy: 0.8562\n",
      "Epoch 490/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8526 - val_loss: 0.3716 - val_accuracy: 0.8581\n",
      "Epoch 491/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8548 - val_loss: 0.3561 - val_accuracy: 0.8600\n",
      "Epoch 492/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.8541 - val_loss: 0.3804 - val_accuracy: 0.8610\n",
      "Epoch 493/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8541 - val_loss: 0.4032 - val_accuracy: 0.8514\n",
      "Epoch 494/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8539 - val_loss: 0.3718 - val_accuracy: 0.8562\n",
      "Epoch 495/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8538 - val_loss: 0.3733 - val_accuracy: 0.8562\n",
      "Epoch 496/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8551 - val_loss: 0.3549 - val_accuracy: 0.8590\n",
      "Epoch 497/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8524 - val_loss: 0.3705 - val_accuracy: 0.8590\n",
      "Epoch 498/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8518 - val_loss: 0.4091 - val_accuracy: 0.8562\n",
      "Epoch 499/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8521 - val_loss: 0.3551 - val_accuracy: 0.8600\n",
      "Epoch 500/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8529 - val_loss: 0.3673 - val_accuracy: 0.8571\n",
      "Epoch 501/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8533 - val_loss: 0.3692 - val_accuracy: 0.8571\n",
      "Epoch 502/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8516 - val_loss: 0.3712 - val_accuracy: 0.8581\n",
      "Epoch 503/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8523 - val_loss: 0.3729 - val_accuracy: 0.8581\n",
      "Epoch 504/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8526 - val_loss: 0.3716 - val_accuracy: 0.8562\n",
      "Epoch 505/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8534 - val_loss: 0.4415 - val_accuracy: 0.8495\n",
      "Epoch 506/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8528 - val_loss: 0.3704 - val_accuracy: 0.8562\n",
      "Epoch 507/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8531 - val_loss: 0.3869 - val_accuracy: 0.8514\n",
      "Epoch 508/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8533 - val_loss: 0.4008 - val_accuracy: 0.8524\n",
      "Epoch 509/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8511 - val_loss: 0.3664 - val_accuracy: 0.8600\n",
      "Epoch 510/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8533 - val_loss: 0.3856 - val_accuracy: 0.8552\n",
      "Epoch 511/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8550 - val_loss: 0.3734 - val_accuracy: 0.8581\n",
      "Epoch 512/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8541 - val_loss: 0.3953 - val_accuracy: 0.8581\n",
      "Epoch 513/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8533 - val_loss: 0.3712 - val_accuracy: 0.8562\n",
      "Epoch 514/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8539 - val_loss: 0.4295 - val_accuracy: 0.8514\n",
      "Epoch 515/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8545 - val_loss: 0.3810 - val_accuracy: 0.8590\n",
      "Epoch 516/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8543 - val_loss: 0.3720 - val_accuracy: 0.8581\n",
      "Epoch 517/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8526 - val_loss: 0.4102 - val_accuracy: 0.8562\n",
      "Epoch 518/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8546 - val_loss: 0.3634 - val_accuracy: 0.8600\n",
      "Epoch 519/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8550 - val_loss: 0.3838 - val_accuracy: 0.8543\n",
      "Epoch 520/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8519 - val_loss: 0.3752 - val_accuracy: 0.8590\n",
      "Epoch 521/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8541 - val_loss: 0.3624 - val_accuracy: 0.8581\n",
      "Epoch 522/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8528 - val_loss: 0.3895 - val_accuracy: 0.8562\n",
      "Epoch 523/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8563 - val_loss: 0.3687 - val_accuracy: 0.8600\n",
      "Epoch 524/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8548 - val_loss: 0.3867 - val_accuracy: 0.8610\n",
      "Epoch 525/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.8539 - val_loss: 0.3618 - val_accuracy: 0.8590\n",
      "Epoch 526/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8550 - val_loss: 0.4074 - val_accuracy: 0.8600\n",
      "Epoch 527/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8543 - val_loss: 0.3717 - val_accuracy: 0.8571\n",
      "Epoch 528/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8529 - val_loss: 0.3717 - val_accuracy: 0.8581\n",
      "Epoch 529/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.8533 - val_loss: 0.3623 - val_accuracy: 0.8619\n",
      "Epoch 530/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8553 - val_loss: 0.4154 - val_accuracy: 0.8610\n",
      "Epoch 531/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8548 - val_loss: 0.3824 - val_accuracy: 0.8562\n",
      "Epoch 532/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3948 - accuracy: 0.8526 - val_loss: 0.4519 - val_accuracy: 0.8495\n",
      "Epoch 533/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8529 - val_loss: 0.4418 - val_accuracy: 0.8495\n",
      "Epoch 534/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8533 - val_loss: 0.3738 - val_accuracy: 0.8600\n",
      "Epoch 535/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8528 - val_loss: 0.3906 - val_accuracy: 0.8571\n",
      "Epoch 536/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8538 - val_loss: 0.3926 - val_accuracy: 0.8571\n",
      "Epoch 537/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8545 - val_loss: 0.3968 - val_accuracy: 0.8495\n",
      "Epoch 538/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8536 - val_loss: 0.3577 - val_accuracy: 0.8590\n",
      "Epoch 539/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8523 - val_loss: 0.3636 - val_accuracy: 0.8590\n",
      "Epoch 540/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8533 - val_loss: 0.4124 - val_accuracy: 0.8581\n",
      "Epoch 541/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8518 - val_loss: 0.3952 - val_accuracy: 0.8600\n",
      "Epoch 542/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8531 - val_loss: 0.4335 - val_accuracy: 0.8486\n",
      "Epoch 543/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8526 - val_loss: 0.3540 - val_accuracy: 0.8581\n",
      "Epoch 544/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8543 - val_loss: 0.3772 - val_accuracy: 0.8600\n",
      "Epoch 545/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8529 - val_loss: 0.3736 - val_accuracy: 0.8600\n",
      "Epoch 546/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8516 - val_loss: 0.3786 - val_accuracy: 0.8610\n",
      "Epoch 547/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8533 - val_loss: 0.3833 - val_accuracy: 0.8552\n",
      "Epoch 548/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8538 - val_loss: 0.3677 - val_accuracy: 0.8600\n",
      "Epoch 549/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8541 - val_loss: 0.4250 - val_accuracy: 0.8495\n",
      "Epoch 550/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8526 - val_loss: 0.3691 - val_accuracy: 0.8619\n",
      "Epoch 551/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8546 - val_loss: 0.3731 - val_accuracy: 0.8581\n",
      "Epoch 552/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8539 - val_loss: 0.3965 - val_accuracy: 0.8562\n",
      "Epoch 553/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8539 - val_loss: 0.3928 - val_accuracy: 0.8590\n",
      "Epoch 554/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8548 - val_loss: 0.3825 - val_accuracy: 0.8552\n",
      "Epoch 555/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8538 - val_loss: 0.4157 - val_accuracy: 0.8571\n",
      "Epoch 556/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8538 - val_loss: 0.3645 - val_accuracy: 0.8590\n",
      "Epoch 557/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8541 - val_loss: 0.3651 - val_accuracy: 0.8590\n",
      "Epoch 558/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8541 - val_loss: 0.3634 - val_accuracy: 0.8600\n",
      "Epoch 559/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8516 - val_loss: 0.3845 - val_accuracy: 0.8533\n",
      "Epoch 560/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8531 - val_loss: 0.3897 - val_accuracy: 0.8619\n",
      "Epoch 561/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8536 - val_loss: 0.3666 - val_accuracy: 0.8610\n",
      "Epoch 562/600\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8516 - val_loss: 0.3859 - val_accuracy: 0.8581\n",
      "Epoch 563/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8518 - val_loss: 0.3871 - val_accuracy: 0.8581\n",
      "Epoch 564/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8531 - val_loss: 0.3779 - val_accuracy: 0.8581\n",
      "Epoch 565/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8534 - val_loss: 0.3815 - val_accuracy: 0.8562\n",
      "Epoch 566/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8548 - val_loss: 0.3831 - val_accuracy: 0.8543\n",
      "Epoch 567/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8526 - val_loss: 0.3770 - val_accuracy: 0.8562\n",
      "Epoch 568/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8533 - val_loss: 0.3910 - val_accuracy: 0.8581\n",
      "Epoch 569/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8558 - val_loss: 0.3741 - val_accuracy: 0.8571\n",
      "Epoch 570/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8536 - val_loss: 0.3934 - val_accuracy: 0.8600\n",
      "Epoch 571/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.8556 - val_loss: 0.3913 - val_accuracy: 0.8581\n",
      "Epoch 572/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8536 - val_loss: 0.3677 - val_accuracy: 0.8571\n",
      "Epoch 573/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8545 - val_loss: 0.3668 - val_accuracy: 0.8600\n",
      "Epoch 574/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.8529 - val_loss: 0.3862 - val_accuracy: 0.8581\n",
      "Epoch 575/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.8560 - val_loss: 0.3747 - val_accuracy: 0.8590\n",
      "Epoch 576/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8538 - val_loss: 0.3894 - val_accuracy: 0.8619\n",
      "Epoch 577/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8523 - val_loss: 0.3775 - val_accuracy: 0.8590\n",
      "Epoch 578/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8534 - val_loss: 0.4034 - val_accuracy: 0.8600\n",
      "Epoch 579/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8545 - val_loss: 0.3762 - val_accuracy: 0.8562\n",
      "Epoch 580/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8545 - val_loss: 0.3858 - val_accuracy: 0.8590\n",
      "Epoch 581/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8529 - val_loss: 0.3798 - val_accuracy: 0.8562\n",
      "Epoch 582/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8550 - val_loss: 0.3724 - val_accuracy: 0.8638\n",
      "Epoch 583/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8546 - val_loss: 0.4193 - val_accuracy: 0.8590\n",
      "Epoch 584/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.8551 - val_loss: 0.3647 - val_accuracy: 0.8610\n",
      "Epoch 585/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8545 - val_loss: 0.3661 - val_accuracy: 0.8629\n",
      "Epoch 586/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8551 - val_loss: 0.3689 - val_accuracy: 0.8619\n",
      "Epoch 587/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8550 - val_loss: 0.4370 - val_accuracy: 0.8495\n",
      "Epoch 588/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8551 - val_loss: 0.3898 - val_accuracy: 0.8581\n",
      "Epoch 589/600\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8533 - val_loss: 0.4002 - val_accuracy: 0.8495\n",
      "Epoch 590/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8516 - val_loss: 0.3899 - val_accuracy: 0.8600\n",
      "Epoch 591/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8553 - val_loss: 0.3833 - val_accuracy: 0.8562\n",
      "Epoch 592/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8528 - val_loss: 0.3902 - val_accuracy: 0.8581\n",
      "Epoch 593/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8519 - val_loss: 0.3653 - val_accuracy: 0.8581\n",
      "Epoch 594/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8538 - val_loss: 0.3833 - val_accuracy: 0.8562\n",
      "Epoch 595/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8536 - val_loss: 0.3720 - val_accuracy: 0.8610\n",
      "Epoch 596/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8545 - val_loss: 0.3931 - val_accuracy: 0.8571\n",
      "Epoch 597/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8545 - val_loss: 0.3852 - val_accuracy: 0.8562\n",
      "Epoch 598/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8536 - val_loss: 0.3992 - val_accuracy: 0.8533\n",
      "Epoch 599/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8541 - val_loss: 0.3907 - val_accuracy: 0.8581\n",
      "Epoch 600/600\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8539 - val_loss: 0.3913 - val_accuracy: 0.8590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26e51ef7a30>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, y = y_train, validation_split = 0.15, batch_size = 55, epochs = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(10, 15) dtype=float32, numpy=\n",
       " array([[ 4.14181054e-01, -3.62968049e-03, -2.38149598e-01,\n",
       "         -1.20092817e-01,  5.21996617e-01, -9.49451774e-02,\n",
       "          1.18435891e-02, -3.05828685e-03, -5.84549233e-02,\n",
       "         -2.15106994e-01, -1.84191778e-01, -5.94859049e-02,\n",
       "          5.56178749e-01,  1.35402411e-01,  2.21296236e-01],\n",
       "        [ 2.14468509e-01,  1.77905589e-01, -3.73022288e-01,\n",
       "         -2.26064742e-01, -3.68637145e-02,  8.41740072e-02,\n",
       "          1.77510291e-01,  3.97631615e-01,  1.04671568e-01,\n",
       "          2.62478322e-01,  1.84176713e-01, -3.39196682e-01,\n",
       "         -2.38463968e-01,  3.86029094e-01,  3.23095351e-01],\n",
       "        [ 2.69470483e-01,  4.03602868e-01, -3.79889965e-01,\n",
       "         -1.75860018e-01,  1.38108283e-01,  4.47377294e-01,\n",
       "          4.34410125e-01,  3.34819943e-01,  4.04517502e-01,\n",
       "          3.07716638e-01, -1.82206511e-01, -4.36278194e-01,\n",
       "         -4.62883085e-01, -1.30897582e-01, -3.95851016e-01],\n",
       "        [ 1.30990219e+00, -5.89634895e-01,  4.51751089e+00,\n",
       "          7.28722930e-01, -2.02601242e+00,  5.46740198e+00,\n",
       "          1.87815082e+00, -1.98476481e+00,  1.63162732e+00,\n",
       "          6.82229578e-01, -1.23612452e+00,  1.25673664e+00,\n",
       "         -9.16863620e-01,  5.35090983e-01, -4.89272982e-01],\n",
       "        [ 6.74852669e-01,  5.82974479e-02,  7.33171523e-01,\n",
       "          4.68403706e-03,  8.64942133e-01, -6.69268966e-02,\n",
       "         -5.45987114e-02, -2.52846539e-01, -4.28662747e-02,\n",
       "          4.55367491e-02, -8.50500911e-02,  2.64231503e-01,\n",
       "          4.01967198e-01, -1.53524116e-01, -2.53225207e-01],\n",
       "        [ 2.52234995e-01, -7.62925982e-01,  6.50406033e-02,\n",
       "          2.66875654e-01, -5.24587557e-02,  3.70271891e-01,\n",
       "         -6.06500283e-02,  7.81523943e-01, -8.86388183e-01,\n",
       "          6.05229318e-01,  2.54695594e-01,  5.71575165e-01,\n",
       "         -2.80568838e-01,  3.92549157e-01, -2.06883758e-01],\n",
       "        [ 7.06424788e-02, -1.41575599e+00, -8.09243023e-01,\n",
       "          8.66427898e-01, -2.67086220e+00,  1.13540828e+00,\n",
       "         -8.10043141e-03, -1.29884183e-01, -1.28218937e+01,\n",
       "          4.39530164e-01, -1.79256546e+00,  1.35295224e+00,\n",
       "         -2.53621101e+00,  1.06300032e+00, -9.12808299e-01],\n",
       "        [-4.26902831e-01, -2.14600116e-01,  1.68268263e-01,\n",
       "         -1.84396654e-01,  3.96083623e-01,  9.36740488e-02,\n",
       "         -7.18364120e-02, -4.78379756e-01, -1.22908494e-02,\n",
       "         -1.99598670e-01, -5.90103231e-02, -3.28815579e-02,\n",
       "         -3.21095020e-01,  1.07125275e-01, -2.14522317e-01],\n",
       "        [-4.43325311e-01,  1.13079965e+00, -2.89055395e+00,\n",
       "         -9.42065418e-01,  1.53233767e+00, -4.07403994e+00,\n",
       "         -2.67376304e-01,  4.96155135e-02, -5.96350968e-01,\n",
       "         -6.31510735e-01,  1.48639643e+00, -1.31915772e+00,\n",
       "          1.23148847e+00, -1.06898308e+00,  1.02943492e+00],\n",
       "        [-3.13956320e-01,  8.32338557e-02,  5.30095339e-01,\n",
       "          4.01803702e-01,  4.96622682e-01,  5.99194944e-01,\n",
       "         -8.53425860e-02, -2.20219836e-01, -6.77510584e-03,\n",
       "          4.10309672e-01, -1.71133697e-01, -2.29319215e-01,\n",
       "         -4.09120053e-01, -7.84710497e-02, -2.87416697e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(15,) dtype=float32, numpy=\n",
       " array([-0.06016909,  0.30533355, -0.39451325, -0.30115885,  1.059739  ,\n",
       "        -0.5781194 , -0.15158643,  0.18830737, -0.39867413, -0.21741912,\n",
       "         0.46144944, -0.43127584,  0.19025598, -0.31923908,  0.24046476],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(15, 10) dtype=float32, numpy=\n",
       " array([[ 4.2047784e-01,  3.3123323e-01, -6.2689716e-01, -3.9209384e-01,\n",
       "         -5.1390314e-01, -3.9605731e-01,  5.0576973e-01,  3.5360621e-03,\n",
       "         -6.7761011e-02, -2.9773003e-01],\n",
       "        [-1.2828171e+00, -5.4545546e-01,  7.6265454e-01,  9.3126494e-01,\n",
       "          1.8279438e-01,  4.3508792e-01, -7.1218587e-02,  5.6799120e-01,\n",
       "          5.6116724e-01,  8.2875311e-01],\n",
       "        [-1.1406866e-01, -1.0216365e+00,  1.0231140e+00,  1.2655848e+00,\n",
       "          1.1098331e+00,  9.9801165e-01, -1.0004963e+00,  6.9557625e-01,\n",
       "          3.6613527e-01,  6.5278119e-01],\n",
       "        [ 5.0701737e-01,  6.8203521e-01, -1.6175158e-01, -5.6704366e-01,\n",
       "         -7.6199090e-01, -5.1170474e-01,  7.2109640e-01, -8.2363451e-01,\n",
       "         -4.9284142e-01, -5.8647317e-01],\n",
       "        [-1.1368971e+00,  2.1588944e-01,  5.3020358e-01,  1.2355174e-01,\n",
       "          5.2862370e-01, -1.8879139e-01, -7.9151936e-02,  6.7734939e-01,\n",
       "          4.4430947e-01,  6.8405908e-01],\n",
       "        [ 4.5479888e-01, -7.2062659e-01,  1.0259997e+00,  3.8597697e-01,\n",
       "          5.7350647e-01,  8.7686956e-01, -1.4757909e+00, -5.2326068e-02,\n",
       "          6.2677145e-01,  1.1829674e+00],\n",
       "        [ 5.0026757e-01, -1.1218912e-03, -8.2844752e-01, -9.7251809e-01,\n",
       "         -8.6674142e-01, -7.6433885e-01,  8.6841512e-01, -2.0332275e-01,\n",
       "         -9.3417370e-01, -7.8775603e-01],\n",
       "        [-1.9084554e+00, -3.1764489e-02,  8.5072726e-01,  8.7770718e-01,\n",
       "          8.1703657e-01,  5.0554508e-01, -8.6898005e-01,  5.7325166e-01,\n",
       "          9.4221056e-01,  5.2347732e-01],\n",
       "        [ 1.6764320e+00,  1.3038721e+00, -1.2819089e+00, -1.3822867e+00,\n",
       "         -1.4434026e+00, -1.4862283e+00,  9.2460036e-01, -8.8213646e-01,\n",
       "         -8.1243455e-01, -1.6795604e+00],\n",
       "        [ 5.7622546e-01,  3.2865971e-01, -9.4977921e-01, -7.5383294e-01,\n",
       "         -9.2808551e-01, -7.7411860e-01,  8.9580822e-01, -1.0149103e+00,\n",
       "         -7.9625094e-01, -5.9457165e-01],\n",
       "        [-1.0551487e+00, -2.0484096e-01, -2.5551695e-01,  3.8985461e-01,\n",
       "          1.4452180e-01, -1.0362400e-02, -2.6931244e-01,  7.1999407e-01,\n",
       "          5.8839446e-01,  9.5934413e-02],\n",
       "        [ 4.5182484e-01,  5.0682378e-01, -4.5003709e-01, -6.1291598e-02,\n",
       "          2.8488647e-02, -2.9090688e-01, -5.9850477e-02, -9.9983126e-02,\n",
       "         -6.8389475e-01, -4.6944398e-01],\n",
       "        [-9.1625243e-01, -7.9586491e-02, -3.3054078e-01,  5.2588135e-01,\n",
       "          4.3086785e-01,  3.4864463e-02,  2.0426138e-01, -5.8411583e-02,\n",
       "          2.0507716e-01, -2.3100482e-01],\n",
       "        [ 3.2296753e-01,  3.4030852e-01, -6.8548340e-01, -6.6880739e-01,\n",
       "         -4.0483925e-01, -1.2256418e-01,  3.4237817e-01, -8.8197130e-01,\n",
       "         -6.0606062e-01, -4.5984201e-02],\n",
       "        [-8.9016044e-01, -5.3735030e-01,  7.4186534e-01,  3.4211278e-01,\n",
       "          7.9521269e-01,  7.4700052e-01, -2.1685642e-01,  4.0468559e-01,\n",
       "          6.6765195e-01, -1.8691517e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([-0.32772386,  0.03632123, -0.0380981 , -0.07721932, -0.04547091,\n",
       "        -0.14679343,  0.07577629, -0.1291656 , -0.03493074, -0.17166296],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(10, 5) dtype=float32, numpy=\n",
       " array([[ 0.31483835, -2.2134519 ,  0.53259945,  2.2371173 , -1.1298954 ],\n",
       "        [ 0.8156096 , -1.0352356 ,  0.8282042 ,  0.97018164, -0.37891337],\n",
       "        [-0.30653504,  1.0194724 , -0.65756565, -0.9833632 ,  0.9112824 ],\n",
       "        [-0.6706349 ,  0.977874  , -0.13358442, -0.7501937 ,  0.39067048],\n",
       "        [-0.31747368,  0.612876  , -0.8719343 , -0.65396386, -0.0311315 ],\n",
       "        [ 0.07324671,  0.5242339 , -0.05556198, -0.6513887 ,  0.43743622],\n",
       "        [ 0.46091637, -0.45392117,  0.04746792,  0.9325066 , -0.6550277 ],\n",
       "        [ 0.3581008 ,  0.7739904 ,  0.21000396, -0.35049897,  0.4899947 ],\n",
       "        [ 0.21721505,  0.5762192 ,  0.28201938, -0.72230935,  0.25003228],\n",
       "        [-0.03052691,  0.04328976, -0.64219964, -0.5910028 ,  0.5261152 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(5,) dtype=float32, numpy=\n",
       " array([ 0.08487968, -0.42605886,  0.08204284,  0.2951389 , -0.22987303],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(5, 1) dtype=float32, numpy=\n",
       " array([[ 0.6465415 ],\n",
       "        [-1.0119898 ],\n",
       "        [ 0.52940845],\n",
       "        [ 2.171653  ],\n",
       "        [-0.3877776 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(1,) dtype=float32, numpy=array([0.12286465], dtype=float32)>]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.5114372968673706,\n",
       "  0.5087417364120483,\n",
       "  0.506001889705658,\n",
       "  0.5034289956092834,\n",
       "  0.5001219511032104,\n",
       "  0.49685904383659363,\n",
       "  0.4923250079154968,\n",
       "  0.48898249864578247,\n",
       "  0.4852356016635895,\n",
       "  0.4814002513885498,\n",
       "  0.47841694951057434,\n",
       "  0.4764477014541626,\n",
       "  0.47414958477020264,\n",
       "  0.4723721444606781,\n",
       "  0.47142529487609863,\n",
       "  0.4710880517959595,\n",
       "  0.47349822521209717,\n",
       "  0.4710537791252136,\n",
       "  0.4713381230831146,\n",
       "  0.4723007380962372,\n",
       "  0.47089964151382446,\n",
       "  0.469964861869812,\n",
       "  0.4698926508426666,\n",
       "  0.46723639965057373,\n",
       "  0.4669361710548401,\n",
       "  0.46934524178504944,\n",
       "  0.4643303453922272,\n",
       "  0.46782952547073364,\n",
       "  0.4625318944454193,\n",
       "  0.47077783942222595,\n",
       "  0.4653518795967102,\n",
       "  0.4672107696533203,\n",
       "  0.48099637031555176,\n",
       "  0.46491530537605286,\n",
       "  0.46896061301231384,\n",
       "  0.472432017326355,\n",
       "  0.468790739774704,\n",
       "  0.46912407875061035,\n",
       "  0.46479541063308716,\n",
       "  0.4684438705444336,\n",
       "  0.46490636467933655,\n",
       "  0.47581014037132263,\n",
       "  0.46908485889434814,\n",
       "  0.4652537405490875,\n",
       "  0.4619610905647278,\n",
       "  0.4661576747894287,\n",
       "  0.4674631655216217,\n",
       "  0.4710940420627594,\n",
       "  0.46789103746414185,\n",
       "  0.46760129928588867,\n",
       "  0.4668698310852051,\n",
       "  0.469547837972641,\n",
       "  0.46272480487823486,\n",
       "  0.4662771224975586,\n",
       "  0.4686620235443115,\n",
       "  0.46770545840263367,\n",
       "  0.47118130326271057,\n",
       "  0.4662472903728485,\n",
       "  0.46600955724716187,\n",
       "  0.46578899025917053,\n",
       "  0.4678192436695099,\n",
       "  0.4654463529586792,\n",
       "  0.4630303680896759,\n",
       "  0.4634856581687927,\n",
       "  0.46275657415390015,\n",
       "  0.46863481402397156,\n",
       "  0.4715069830417633,\n",
       "  0.4677233099937439,\n",
       "  0.469467431306839,\n",
       "  0.4640059173107147,\n",
       "  0.46365487575531006,\n",
       "  0.4676285982131958,\n",
       "  0.4642986059188843,\n",
       "  0.47362691164016724,\n",
       "  0.46654194593429565,\n",
       "  0.4740326404571533,\n",
       "  0.47355300188064575,\n",
       "  0.4719473421573639,\n",
       "  0.4714055061340332,\n",
       "  0.46307915449142456,\n",
       "  0.4650910794734955,\n",
       "  0.46721306443214417,\n",
       "  0.4740956425666809,\n",
       "  0.46995437145233154,\n",
       "  0.4781619608402252,\n",
       "  0.4681493043899536,\n",
       "  0.4618676006793976,\n",
       "  0.4646032750606537,\n",
       "  0.4590078890323639,\n",
       "  0.467613160610199,\n",
       "  0.4671860933303833,\n",
       "  0.46639320254325867,\n",
       "  0.46112552285194397,\n",
       "  0.46222123503685,\n",
       "  0.460540771484375,\n",
       "  0.460726261138916,\n",
       "  0.45834383368492126,\n",
       "  0.464735746383667,\n",
       "  0.46528327465057373,\n",
       "  0.4642329812049866,\n",
       "  0.4647529423236847,\n",
       "  0.4623664319515228,\n",
       "  0.4623645544052124,\n",
       "  0.46518564224243164,\n",
       "  0.4614788293838501,\n",
       "  0.4603724181652069,\n",
       "  0.45907390117645264,\n",
       "  0.4592248499393463,\n",
       "  0.4706590473651886,\n",
       "  0.4668516516685486,\n",
       "  0.4584217071533203,\n",
       "  0.4577094614505768,\n",
       "  0.45876842737197876,\n",
       "  0.4586809575557709,\n",
       "  0.4633057415485382,\n",
       "  0.45850902795791626,\n",
       "  0.4580305516719818,\n",
       "  0.45770713686943054,\n",
       "  0.46239569783210754,\n",
       "  0.45906201004981995,\n",
       "  0.46453502774238586,\n",
       "  0.4588869512081146,\n",
       "  0.46156245470046997,\n",
       "  0.4638574719429016,\n",
       "  0.4597005546092987,\n",
       "  0.46622514724731445,\n",
       "  0.4567166864871979,\n",
       "  0.46040579676628113,\n",
       "  0.4613190293312073,\n",
       "  0.4505881071090698,\n",
       "  0.4585948586463928,\n",
       "  0.4627632200717926,\n",
       "  0.45509371161460876,\n",
       "  0.45659351348876953,\n",
       "  0.4562753438949585,\n",
       "  0.4550551474094391,\n",
       "  0.45381754636764526,\n",
       "  0.4534348249435425,\n",
       "  0.4485575556755066,\n",
       "  0.45080122351646423,\n",
       "  0.45326822996139526,\n",
       "  0.45139336585998535,\n",
       "  0.4560914635658264,\n",
       "  0.4488275647163391,\n",
       "  0.44963473081588745,\n",
       "  0.44831132888793945,\n",
       "  0.4519255459308624,\n",
       "  0.44865575432777405,\n",
       "  0.45681729912757874,\n",
       "  0.44698870182037354,\n",
       "  0.44546210765838623,\n",
       "  0.44758275151252747,\n",
       "  0.44807371497154236,\n",
       "  0.44702041149139404,\n",
       "  0.44781365990638733,\n",
       "  0.4484855830669403,\n",
       "  0.4458920359611511,\n",
       "  0.45017433166503906,\n",
       "  0.44943469762802124,\n",
       "  0.443840354681015,\n",
       "  0.44491609930992126,\n",
       "  0.4462031126022339,\n",
       "  0.4425656497478485,\n",
       "  0.4417024254798889,\n",
       "  0.4444330334663391,\n",
       "  0.4408251643180847,\n",
       "  0.44588354229927063,\n",
       "  0.441545307636261,\n",
       "  0.4407792091369629,\n",
       "  0.44247567653656006,\n",
       "  0.44043734669685364,\n",
       "  0.4377027750015259,\n",
       "  0.4378341734409332,\n",
       "  0.437145471572876,\n",
       "  0.4375869035720825,\n",
       "  0.43606600165367126,\n",
       "  0.43927091360092163,\n",
       "  0.437441885471344,\n",
       "  0.44140008091926575,\n",
       "  0.4483420252799988,\n",
       "  0.4340711236000061,\n",
       "  0.4396432638168335,\n",
       "  0.4384553134441376,\n",
       "  0.43437278270721436,\n",
       "  0.4327508211135864,\n",
       "  0.4320193827152252,\n",
       "  0.43774721026420593,\n",
       "  0.4297831356525421,\n",
       "  0.4351249933242798,\n",
       "  0.4294570982456207,\n",
       "  0.4345540702342987,\n",
       "  0.4339553117752075,\n",
       "  0.42822420597076416,\n",
       "  0.43578511476516724,\n",
       "  0.4352370500564575,\n",
       "  0.43827420473098755,\n",
       "  0.4307713210582733,\n",
       "  0.4357268810272217,\n",
       "  0.4290831685066223,\n",
       "  0.435393750667572,\n",
       "  0.43279358744621277,\n",
       "  0.4334253966808319,\n",
       "  0.4439082741737366,\n",
       "  0.4297502338886261,\n",
       "  0.43208611011505127,\n",
       "  0.4285314977169037,\n",
       "  0.43286338448524475,\n",
       "  0.42912474274635315,\n",
       "  0.43364766240119934,\n",
       "  0.43171894550323486,\n",
       "  0.4333798587322235,\n",
       "  0.43111854791641235,\n",
       "  0.423622727394104,\n",
       "  0.43093621730804443,\n",
       "  0.4271218180656433,\n",
       "  0.42872512340545654,\n",
       "  0.42458298802375793,\n",
       "  0.4255169630050659,\n",
       "  0.42512595653533936,\n",
       "  0.4255853593349457,\n",
       "  0.4269693195819855,\n",
       "  0.42065709829330444,\n",
       "  0.4161072373390198,\n",
       "  0.42871952056884766,\n",
       "  0.42266255617141724,\n",
       "  0.4174337387084961,\n",
       "  0.4231749475002289,\n",
       "  0.4181264340877533,\n",
       "  0.4185038208961487,\n",
       "  0.4244719445705414,\n",
       "  0.42155998945236206,\n",
       "  0.43644970655441284,\n",
       "  0.42744219303131104,\n",
       "  0.4261150360107422,\n",
       "  0.4172728359699249,\n",
       "  0.418865829706192,\n",
       "  0.41767561435699463,\n",
       "  0.42091724276542664,\n",
       "  0.4198528528213501,\n",
       "  0.4173823893070221,\n",
       "  0.42004016041755676,\n",
       "  0.41315770149230957,\n",
       "  0.4157980680465698,\n",
       "  0.41286179423332214,\n",
       "  0.413289338350296,\n",
       "  0.4181974530220032,\n",
       "  0.41567564010620117,\n",
       "  0.4194202721118927,\n",
       "  0.42034757137298584,\n",
       "  0.40879443287849426,\n",
       "  0.41150009632110596,\n",
       "  0.41131457686424255,\n",
       "  0.4140245318412781,\n",
       "  0.4081820845603943,\n",
       "  0.4108057916164398,\n",
       "  0.4105459451675415,\n",
       "  0.4187326729297638,\n",
       "  0.4181044101715088,\n",
       "  0.4144841134548187,\n",
       "  0.4128396213054657,\n",
       "  0.41334640979766846,\n",
       "  0.4168301820755005,\n",
       "  0.41790077090263367,\n",
       "  0.419238418340683,\n",
       "  0.4242459535598755,\n",
       "  0.4209999144077301,\n",
       "  0.42154940962791443,\n",
       "  0.41569122672080994,\n",
       "  0.41524213552474976,\n",
       "  0.4186042547225952,\n",
       "  0.4229772388935089,\n",
       "  0.4185173809528351,\n",
       "  0.4187737703323364,\n",
       "  0.4176037609577179,\n",
       "  0.4184718132019043,\n",
       "  0.417776882648468,\n",
       "  0.41431644558906555,\n",
       "  0.42110249400138855,\n",
       "  0.40925970673561096,\n",
       "  0.41419875621795654,\n",
       "  0.4053242802619934,\n",
       "  0.4157125651836395,\n",
       "  0.4172087609767914,\n",
       "  0.40872451663017273,\n",
       "  0.4180780053138733,\n",
       "  0.4139164388179779,\n",
       "  0.4094693064689636,\n",
       "  0.4203033447265625,\n",
       "  0.412300169467926,\n",
       "  0.4174637198448181,\n",
       "  0.4176165759563446,\n",
       "  0.4179062247276306,\n",
       "  0.41067826747894287,\n",
       "  0.4174377918243408,\n",
       "  0.40780285000801086,\n",
       "  0.4229293167591095,\n",
       "  0.42105832695961,\n",
       "  0.42116349935531616,\n",
       "  0.40561604499816895,\n",
       "  0.4095296561717987,\n",
       "  0.4030587673187256,\n",
       "  0.40737420320510864,\n",
       "  0.4077506959438324,\n",
       "  0.4046919047832489,\n",
       "  0.40359628200531006,\n",
       "  0.40744641423225403,\n",
       "  0.4100434482097626,\n",
       "  0.4005451798439026,\n",
       "  0.4005829691886902,\n",
       "  0.4069150984287262,\n",
       "  0.401930034160614,\n",
       "  0.41020667552948,\n",
       "  0.4036879241466522,\n",
       "  0.40944933891296387,\n",
       "  0.4069722890853882,\n",
       "  0.40407538414001465,\n",
       "  0.4099386930465698,\n",
       "  0.403693288564682,\n",
       "  0.4003027677536011,\n",
       "  0.39741215109825134,\n",
       "  0.41242343187332153,\n",
       "  0.40884897112846375,\n",
       "  0.4117051959037781,\n",
       "  0.41603586077690125,\n",
       "  0.4094159007072449,\n",
       "  0.41159114241600037,\n",
       "  0.4056535065174103,\n",
       "  0.40504691004753113,\n",
       "  0.40887290239334106,\n",
       "  0.4089580774307251,\n",
       "  0.4011956751346588,\n",
       "  0.41405564546585083,\n",
       "  0.41128644347190857,\n",
       "  0.4043622314929962,\n",
       "  0.40412333607673645,\n",
       "  0.40140509605407715,\n",
       "  0.40320953726768494,\n",
       "  0.39837905764579773,\n",
       "  0.4106958508491516,\n",
       "  0.41491755843162537,\n",
       "  0.39865541458129883,\n",
       "  0.41061022877693176,\n",
       "  0.41225993633270264,\n",
       "  0.4057411551475525,\n",
       "  0.40856626629829407,\n",
       "  0.40303370356559753,\n",
       "  0.40665218234062195,\n",
       "  0.409787118434906,\n",
       "  0.41428717970848083,\n",
       "  0.4058187007904053,\n",
       "  0.4026525020599365,\n",
       "  0.4002382457256317,\n",
       "  0.4052211344242096,\n",
       "  0.40132007002830505,\n",
       "  0.4070703089237213,\n",
       "  0.4067537486553192,\n",
       "  0.39955440163612366,\n",
       "  0.4076918363571167,\n",
       "  0.41080257296562195,\n",
       "  0.40265029668807983,\n",
       "  0.4064302146434784,\n",
       "  0.404511958360672,\n",
       "  0.4077751934528351,\n",
       "  0.39887842535972595,\n",
       "  0.40422672033309937,\n",
       "  0.4113486111164093,\n",
       "  0.3999224007129669,\n",
       "  0.39995822310447693,\n",
       "  0.4042399227619171,\n",
       "  0.4029542803764343,\n",
       "  0.4005546271800995,\n",
       "  0.4049815833568573,\n",
       "  0.4027847647666931,\n",
       "  0.396543949842453,\n",
       "  0.40635615587234497,\n",
       "  0.4084700047969818,\n",
       "  0.4023437798023224,\n",
       "  0.4107002019882202,\n",
       "  0.39554563164711,\n",
       "  0.40190693736076355,\n",
       "  0.4018787741661072,\n",
       "  0.39903727173805237,\n",
       "  0.3967112898826599,\n",
       "  0.4004019498825073,\n",
       "  0.406001478433609,\n",
       "  0.4069889783859253,\n",
       "  0.39982545375823975,\n",
       "  0.39560648798942566,\n",
       "  0.4159577190876007,\n",
       "  0.40243780612945557,\n",
       "  0.39805880188941956,\n",
       "  0.3945727050304413,\n",
       "  0.4064747393131256,\n",
       "  0.3954854905605316,\n",
       "  0.40433529019355774,\n",
       "  0.4034457802772522,\n",
       "  0.4066610038280487,\n",
       "  0.40583717823028564,\n",
       "  0.39962661266326904,\n",
       "  0.40676039457321167,\n",
       "  0.4033016562461853,\n",
       "  0.4029944837093353,\n",
       "  0.40307489037513733,\n",
       "  0.40343648195266724,\n",
       "  0.39786165952682495,\n",
       "  0.3985259532928467,\n",
       "  0.3923683762550354,\n",
       "  0.39574599266052246,\n",
       "  0.39807745814323425,\n",
       "  0.3941606879234314,\n",
       "  0.3999856114387512,\n",
       "  0.39781665802001953,\n",
       "  0.4091765284538269,\n",
       "  0.39365091919898987,\n",
       "  0.39772313833236694,\n",
       "  0.3970520496368408,\n",
       "  0.40173184871673584,\n",
       "  0.4054786264896393,\n",
       "  0.39815691113471985,\n",
       "  0.3929651081562042,\n",
       "  0.39853373169898987,\n",
       "  0.39143186807632446,\n",
       "  0.40897318720817566,\n",
       "  0.41482922434806824,\n",
       "  0.3984788656234741,\n",
       "  0.39763548970222473,\n",
       "  0.3973121643066406,\n",
       "  0.3980383276939392,\n",
       "  0.39369648694992065,\n",
       "  0.3968909680843353,\n",
       "  0.4007951319217682,\n",
       "  0.3966974914073944,\n",
       "  0.41480574011802673,\n",
       "  0.4000968039035797,\n",
       "  0.3946860134601593,\n",
       "  0.4018859565258026,\n",
       "  0.3938541114330292,\n",
       "  0.4063119888305664,\n",
       "  0.4014630913734436,\n",
       "  0.398349404335022,\n",
       "  0.3904690444469452,\n",
       "  0.3975374102592468,\n",
       "  0.4028327763080597,\n",
       "  0.40032899379730225,\n",
       "  0.4047938287258148,\n",
       "  0.39474400877952576,\n",
       "  0.40976980328559875,\n",
       "  0.39767521619796753,\n",
       "  0.40801677107810974,\n",
       "  0.4054137170314789,\n",
       "  0.4000389277935028,\n",
       "  0.4064541459083557,\n",
       "  0.40178003907203674,\n",
       "  0.40126556158065796,\n",
       "  0.403181791305542,\n",
       "  0.39611417055130005,\n",
       "  0.40310031175613403,\n",
       "  0.40388381481170654,\n",
       "  0.40248632431030273,\n",
       "  0.40244367718696594,\n",
       "  0.39532148838043213,\n",
       "  0.3897820711135864,\n",
       "  0.3926551938056946,\n",
       "  0.4018884301185608,\n",
       "  0.39289170503616333,\n",
       "  0.39838486909866333,\n",
       "  0.3957836329936981,\n",
       "  0.4002454876899719,\n",
       "  0.3983626961708069,\n",
       "  0.3980279862880707,\n",
       "  0.3967079222202301,\n",
       "  0.4055614769458771,\n",
       "  0.4092639982700348,\n",
       "  0.39688295125961304,\n",
       "  0.3992217481136322,\n",
       "  0.39408960938453674,\n",
       "  0.3970130681991577,\n",
       "  0.3969528079032898,\n",
       "  0.4048260748386383,\n",
       "  0.4061119258403778,\n",
       "  0.40796801447868347,\n",
       "  0.4006190001964569,\n",
       "  0.4221403896808624,\n",
       "  0.4057922065258026,\n",
       "  0.40263405442237854,\n",
       "  0.39802807569503784,\n",
       "  0.4055193066596985,\n",
       "  0.4002639055252075,\n",
       "  0.39603880047798157,\n",
       "  0.40009450912475586,\n",
       "  0.4012853801250458,\n",
       "  0.39974409341812134,\n",
       "  0.3901026248931885,\n",
       "  0.3965376317501068,\n",
       "  0.4044981300830841,\n",
       "  0.3994670808315277,\n",
       "  0.39949166774749756,\n",
       "  0.40537917613983154,\n",
       "  0.402349591255188,\n",
       "  0.40149980783462524,\n",
       "  0.4087649881839752,\n",
       "  0.3995392620563507,\n",
       "  0.40214166045188904,\n",
       "  0.4058466851711273,\n",
       "  0.4014696776866913,\n",
       "  0.39802393317222595,\n",
       "  0.4026837944984436,\n",
       "  0.404847651720047,\n",
       "  0.41094455122947693,\n",
       "  0.4014906883239746,\n",
       "  0.40970075130462646,\n",
       "  0.40947607159614563,\n",
       "  0.39677894115448,\n",
       "  0.406599760055542,\n",
       "  0.41471749544143677,\n",
       "  0.40643128752708435,\n",
       "  0.41474372148513794,\n",
       "  0.401756227016449,\n",
       "  0.39626801013946533,\n",
       "  0.40043580532073975,\n",
       "  0.3999989628791809,\n",
       "  0.40416228771209717,\n",
       "  0.40714704990386963,\n",
       "  0.40141910314559937,\n",
       "  0.39185014367103577,\n",
       "  0.39647307991981506,\n",
       "  0.40866124629974365,\n",
       "  0.41266176104545593,\n",
       "  0.4025798439979553,\n",
       "  0.3980868458747864,\n",
       "  0.38797590136528015,\n",
       "  0.39482080936431885,\n",
       "  0.415280282497406,\n",
       "  0.4091966450214386,\n",
       "  0.4116847813129425,\n",
       "  0.39884838461875916,\n",
       "  0.4073146879673004,\n",
       "  0.3983745574951172,\n",
       "  0.40742409229278564,\n",
       "  0.4062115550041199,\n",
       "  0.4101529121398926,\n",
       "  0.40209394693374634,\n",
       "  0.40659019351005554,\n",
       "  0.4053417444229126,\n",
       "  0.41492149233818054,\n",
       "  0.4070521891117096,\n",
       "  0.3931926190853119,\n",
       "  0.40864405035972595,\n",
       "  0.3932656943798065,\n",
       "  0.39886265993118286,\n",
       "  0.4089893400669098,\n",
       "  0.4047343134880066,\n",
       "  0.40668371319770813,\n",
       "  0.3945280909538269,\n",
       "  0.40197303891181946,\n",
       "  0.39909714460372925,\n",
       "  0.40349453687667847,\n",
       "  0.4024420976638794,\n",
       "  0.39580878615379333,\n",
       "  0.39486509561538696,\n",
       "  0.40466976165771484,\n",
       "  0.4002779424190521,\n",
       "  0.410704106092453,\n",
       "  0.41271981596946716,\n",
       "  0.4054222106933594,\n",
       "  0.3965723514556885,\n",
       "  0.40671876072883606,\n",
       "  0.4063904583454132,\n",
       "  0.40352267026901245,\n",
       "  0.40720197558403015,\n",
       "  0.414332777261734,\n",
       "  0.4075968861579895,\n",
       "  0.4118958115577698,\n",
       "  0.39965713024139404,\n",
       "  0.39634081721305847,\n",
       "  0.41041553020477295,\n",
       "  0.41823142766952515,\n",
       "  0.409479022026062,\n",
       "  0.40622296929359436,\n",
       "  0.4163084328174591,\n",
       "  0.4152873456478119,\n",
       "  0.40032851696014404,\n",
       "  0.4095011055469513,\n",
       "  0.40281033515930176,\n",
       "  0.4126913249492645,\n",
       "  0.39977723360061646,\n",
       "  0.39897656440734863,\n",
       "  0.4049101769924164,\n",
       "  0.4087287187576294,\n",
       "  0.41818949580192566,\n",
       "  0.39859095215797424,\n",
       "  0.4068200886249542,\n",
       "  0.4154306650161743,\n",
       "  0.3979586660861969,\n",
       "  0.4030280113220215,\n",
       "  0.39978688955307007,\n",
       "  0.3980850875377655,\n",
       "  0.40694209933280945,\n",
       "  0.4019401967525482,\n",
       "  0.405196875333786],\n",
       " 'accuracy': [0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7942857146263123,\n",
       "  0.7946218252182007,\n",
       "  0.7944537997245789,\n",
       "  0.7944537997245789,\n",
       "  0.7941176295280457,\n",
       "  0.7944537997245789,\n",
       "  0.7946218252182007,\n",
       "  0.7944537997245789,\n",
       "  0.7942857146263123,\n",
       "  0.7939496040344238,\n",
       "  0.7947899103164673,\n",
       "  0.7939496040344238,\n",
       "  0.7942857146263123,\n",
       "  0.7949579954147339,\n",
       "  0.7947899103164673,\n",
       "  0.795966386795044,\n",
       "  0.7966386675834656,\n",
       "  0.7956302762031555,\n",
       "  0.7963024973869324,\n",
       "  0.796470582485199,\n",
       "  0.797478973865509,\n",
       "  0.7971428632736206,\n",
       "  0.797478973865509,\n",
       "  0.7961344718933105,\n",
       "  0.7956302762031555,\n",
       "  0.7966386675834656,\n",
       "  0.7971428632736206,\n",
       "  0.7951260209083557,\n",
       "  0.796974778175354,\n",
       "  0.7966386675834656,\n",
       "  0.7954621911048889,\n",
       "  0.7968066930770874,\n",
       "  0.7954621911048889,\n",
       "  0.796974778175354,\n",
       "  0.7963024973869324,\n",
       "  0.7968066930770874,\n",
       "  0.797478973865509,\n",
       "  0.796974778175354,\n",
       "  0.7971428632736206,\n",
       "  0.7951260209083557,\n",
       "  0.795966386795044,\n",
       "  0.7986554503440857,\n",
       "  0.7973109483718872,\n",
       "  0.7971428632736206,\n",
       "  0.7966386675834656,\n",
       "  0.796470582485199,\n",
       "  0.7971428632736206,\n",
       "  0.7986554503440857,\n",
       "  0.7963024973869324,\n",
       "  0.7973109483718872,\n",
       "  0.796974778175354,\n",
       "  0.7976470589637756,\n",
       "  0.7981512546539307,\n",
       "  0.7971428632736206,\n",
       "  0.7996638417243958,\n",
       "  0.7988235354423523,\n",
       "  0.797478973865509,\n",
       "  0.7996638417243958,\n",
       "  0.800504207611084,\n",
       "  0.8008403182029724,\n",
       "  0.7986554503440857,\n",
       "  0.800000011920929,\n",
       "  0.7976470589637756,\n",
       "  0.7983193397521973,\n",
       "  0.7988235354423523,\n",
       "  0.7989916205406189,\n",
       "  0.7989916205406189,\n",
       "  0.7983193397521973,\n",
       "  0.8008403182029724,\n",
       "  0.7993277311325073,\n",
       "  0.7998319268226624,\n",
       "  0.7991596460342407,\n",
       "  0.8006722927093506,\n",
       "  0.7984873652458191,\n",
       "  0.7998319268226624,\n",
       "  0.7996638417243958,\n",
       "  0.7981512546539307,\n",
       "  0.7993277311325073,\n",
       "  0.800000011920929,\n",
       "  0.8008403182029724,\n",
       "  0.8001680970191956,\n",
       "  0.7989916205406189,\n",
       "  0.7993277311325073,\n",
       "  0.800504207611084,\n",
       "  0.8023529648780823,\n",
       "  0.801512598991394,\n",
       "  0.7998319268226624,\n",
       "  0.800504207611084,\n",
       "  0.7998319268226624,\n",
       "  0.801008403301239,\n",
       "  0.8020167946815491,\n",
       "  0.8011764883995056,\n",
       "  0.8013445138931274,\n",
       "  0.8025209903717041,\n",
       "  0.8011764883995056,\n",
       "  0.801008403301239,\n",
       "  0.8030251860618591,\n",
       "  0.8043697476387024,\n",
       "  0.8043697476387024,\n",
       "  0.8028571605682373,\n",
       "  0.8043697476387024,\n",
       "  0.8031932711601257,\n",
       "  0.8043697476387024,\n",
       "  0.8052101135253906,\n",
       "  0.8065546154975891,\n",
       "  0.804033637046814,\n",
       "  0.804033637046814,\n",
       "  0.8042016625404358,\n",
       "  0.8062185049057007,\n",
       "  0.805546224117279,\n",
       "  0.8053781390190125,\n",
       "  0.8058823347091675,\n",
       "  0.8077310919761658,\n",
       "  0.805042028427124,\n",
       "  0.8058823347091675,\n",
       "  0.8057143092155457,\n",
       "  0.805042028427124,\n",
       "  0.8062185049057007,\n",
       "  0.8063865303993225,\n",
       "  0.8067227005958557,\n",
       "  0.809075653553009,\n",
       "  0.8068907856941223,\n",
       "  0.8073949813842773,\n",
       "  0.809075653553009,\n",
       "  0.8087394833564758,\n",
       "  0.8077310919761658,\n",
       "  0.8078991770744324,\n",
       "  0.8078991770744324,\n",
       "  0.8094117641448975,\n",
       "  0.8087394833564758,\n",
       "  0.8092436790466309,\n",
       "  0.8087394833564758,\n",
       "  0.8097478747367859,\n",
       "  0.8107563257217407,\n",
       "  0.8102521300315857,\n",
       "  0.8127731084823608,\n",
       "  0.8104201555252075,\n",
       "  0.8102521300315857,\n",
       "  0.8126050233840942,\n",
       "  0.8115966320037842,\n",
       "  0.8100840449333191,\n",
       "  0.8100840449333191,\n",
       "  0.8114285469055176,\n",
       "  0.8097478747367859,\n",
       "  0.8112605214118958,\n",
       "  0.8099159598350525,\n",
       "  0.8124369978904724,\n",
       "  0.8117647171020508,\n",
       "  0.8115966320037842,\n",
       "  0.8121008276939392,\n",
       "  0.8114285469055176,\n",
       "  0.8105882406234741,\n",
       "  0.8092436790466309,\n",
       "  0.8104201555252075,\n",
       "  0.8121008276939392,\n",
       "  0.8114285469055176,\n",
       "  0.8131092190742493,\n",
       "  0.8104201555252075,\n",
       "  0.8131092190742493,\n",
       "  0.8164705634117126,\n",
       "  0.8124369978904724,\n",
       "  0.8131092190742493,\n",
       "  0.8126050233840942,\n",
       "  0.8139495849609375,\n",
       "  0.8134453892707825,\n",
       "  0.8152941465377808,\n",
       "  0.8142856955528259,\n",
       "  0.8139495849609375,\n",
       "  0.8151260614395142,\n",
       "  0.8149579763412476,\n",
       "  0.814789891242981,\n",
       "  0.8144537806510925,\n",
       "  0.8129411935806274,\n",
       "  0.8127731084823608,\n",
       "  0.8154621720314026,\n",
       "  0.8146218657493591,\n",
       "  0.8156302571296692,\n",
       "  0.8176470398902893,\n",
       "  0.8174790143966675,\n",
       "  0.8164705634117126,\n",
       "  0.8173109292984009,\n",
       "  0.819831907749176,\n",
       "  0.8173109292984009,\n",
       "  0.8184874057769775,\n",
       "  0.819327712059021,\n",
       "  0.8168067336082458,\n",
       "  0.8191596865653992,\n",
       "  0.8183193206787109,\n",
       "  0.8181512355804443,\n",
       "  0.8194957971572876,\n",
       "  0.8184874057769775,\n",
       "  0.8203361630439758,\n",
       "  0.8203361630439758,\n",
       "  0.8216806650161743,\n",
       "  0.8178151249885559,\n",
       "  0.823865532875061,\n",
       "  0.823361337184906,\n",
       "  0.823865532875061,\n",
       "  0.8211764693260193,\n",
       "  0.8235294222831726,\n",
       "  0.8226890563964844,\n",
       "  0.822857141494751,\n",
       "  0.8245378136634827,\n",
       "  0.823361337184906,\n",
       "  0.823361337184906,\n",
       "  0.8252100944519043,\n",
       "  0.8265545964241028,\n",
       "  0.8247058987617493,\n",
       "  0.8242017030715942,\n",
       "  0.8262184858322144,\n",
       "  0.8277310729026794,\n",
       "  0.8262184858322144,\n",
       "  0.826386570930481,\n",
       "  0.8290756344795227,\n",
       "  0.8282352685928345,\n",
       "  0.8284033536911011,\n",
       "  0.8262184858322144,\n",
       "  0.826890766620636,\n",
       "  0.8295798301696777,\n",
       "  0.8287395238876343,\n",
       "  0.8295798301696777,\n",
       "  0.8277310729026794,\n",
       "  0.8272268772125244,\n",
       "  0.8312605023384094,\n",
       "  0.8297479152679443,\n",
       "  0.8315966129302979,\n",
       "  0.8317646980285645,\n",
       "  0.8331092596054077,\n",
       "  0.8317646980285645,\n",
       "  0.8315966129302979,\n",
       "  0.8339495658874512,\n",
       "  0.8315966129302979,\n",
       "  0.8346218466758728,\n",
       "  0.8352941274642944,\n",
       "  0.8321008682250977,\n",
       "  0.8344537615776062,\n",
       "  0.8342857360839844,\n",
       "  0.8379831910133362,\n",
       "  0.8383193016052246,\n",
       "  0.8368067145347595,\n",
       "  0.8371428847312927,\n",
       "  0.8366386294364929,\n",
       "  0.8346218466758728,\n",
       "  0.8369747996330261,\n",
       "  0.8363025188446045,\n",
       "  0.8376470804214478,\n",
       "  0.8426890969276428,\n",
       "  0.8408403396606445,\n",
       "  0.8420168161392212,\n",
       "  0.8396638631820679,\n",
       "  0.8388235569000244,\n",
       "  0.8415126204490662,\n",
       "  0.8394957780838013,\n",
       "  0.8433613181114197,\n",
       "  0.8423529267311096,\n",
       "  0.841680645942688,\n",
       "  0.8406722545623779,\n",
       "  0.8401680588722229,\n",
       "  0.8425210118293762,\n",
       "  0.8433613181114197,\n",
       "  0.8418487310409546,\n",
       "  0.8403361439704895,\n",
       "  0.8435294032096863,\n",
       "  0.8431932926177979,\n",
       "  0.8425210118293762,\n",
       "  0.8428571224212646,\n",
       "  0.8450419902801514,\n",
       "  0.8443697690963745,\n",
       "  0.8447058796882629,\n",
       "  0.8431932926177979,\n",
       "  0.8443697690963745,\n",
       "  0.8440335988998413,\n",
       "  0.845714271068573,\n",
       "  0.8443697690963745,\n",
       "  0.845714271068573,\n",
       "  0.8455462455749512,\n",
       "  0.841680645942688,\n",
       "  0.8366386294364929,\n",
       "  0.8413445353507996,\n",
       "  0.845714271068573,\n",
       "  0.8428571224212646,\n",
       "  0.8406722545623779,\n",
       "  0.8438655734062195,\n",
       "  0.8431932926177979,\n",
       "  0.8442016839981079,\n",
       "  0.8442016839981079,\n",
       "  0.8447058796882629,\n",
       "  0.8433613181114197,\n",
       "  0.845714271068573,\n",
       "  0.8458823561668396,\n",
       "  0.8455462455749512,\n",
       "  0.8442016839981079,\n",
       "  0.8470588326454163,\n",
       "  0.8465546369552612,\n",
       "  0.8458823561668396,\n",
       "  0.8468907475471497,\n",
       "  0.8430252075195312,\n",
       "  0.8440335988998413,\n",
       "  0.845714271068573,\n",
       "  0.8455462455749512,\n",
       "  0.8450419902801514,\n",
       "  0.8426890969276428,\n",
       "  0.8480672240257263,\n",
       "  0.849243700504303,\n",
       "  0.8468907475471497,\n",
       "  0.8475630283355713,\n",
       "  0.8467226624488831,\n",
       "  0.8480672240257263,\n",
       "  0.8480672240257263,\n",
       "  0.845210075378418,\n",
       "  0.8468907475471497,\n",
       "  0.8467226624488831,\n",
       "  0.8489075899124146,\n",
       "  0.8445377945899963,\n",
       "  0.8484033346176147,\n",
       "  0.8478991389274597,\n",
       "  0.8482353091239929,\n",
       "  0.8482353091239929,\n",
       "  0.8482353091239929,\n",
       "  0.8468907475471497,\n",
       "  0.8484033346176147,\n",
       "  0.8507562875747681,\n",
       "  0.8504201769828796,\n",
       "  0.8468907475471497,\n",
       "  0.8470588326454163,\n",
       "  0.8477311134338379,\n",
       "  0.8470588326454163,\n",
       "  0.8490756154060364,\n",
       "  0.8480672240257263,\n",
       "  0.8480672240257263,\n",
       "  0.848739504814148,\n",
       "  0.8485714197158813,\n",
       "  0.8450419902801514,\n",
       "  0.8443697690963745,\n",
       "  0.8499159812927246,\n",
       "  0.8485714197158813,\n",
       "  0.848739504814148,\n",
       "  0.846218466758728,\n",
       "  0.849243700504303,\n",
       "  0.8467226624488831,\n",
       "  0.8468907475471497,\n",
       "  0.848739504814148,\n",
       "  0.8494117856025696,\n",
       "  0.8468907475471497,\n",
       "  0.8500840067863464,\n",
       "  0.8507562875747681,\n",
       "  0.8499159812927246,\n",
       "  0.849243700504303,\n",
       "  0.8482353091239929,\n",
       "  0.848739504814148,\n",
       "  0.849243700504303,\n",
       "  0.8507562875747681,\n",
       "  0.850252091884613,\n",
       "  0.8485714197158813,\n",
       "  0.8514285683631897,\n",
       "  0.8499159812927246,\n",
       "  0.8460504412651062,\n",
       "  0.8494117856025696,\n",
       "  0.8494117856025696,\n",
       "  0.8514285683631897,\n",
       "  0.8495798110961914,\n",
       "  0.8500840067863464,\n",
       "  0.8512604832649231,\n",
       "  0.8489075899124146,\n",
       "  0.8473949432373047,\n",
       "  0.8510924577713013,\n",
       "  0.8477311134338379,\n",
       "  0.8505882620811462,\n",
       "  0.850252091884613,\n",
       "  0.8507562875747681,\n",
       "  0.8470588326454163,\n",
       "  0.8524369597434998,\n",
       "  0.8514285683631897,\n",
       "  0.8478991389274597,\n",
       "  0.8509243726730347,\n",
       "  0.853277325630188,\n",
       "  0.8517646789550781,\n",
       "  0.8512604832649231,\n",
       "  0.8495798110961914,\n",
       "  0.8510924577713013,\n",
       "  0.8514285683631897,\n",
       "  0.8522689342498779,\n",
       "  0.8521008491516113,\n",
       "  0.850252091884613,\n",
       "  0.850252091884613,\n",
       "  0.8510924577713013,\n",
       "  0.8494117856025696,\n",
       "  0.8512604832649231,\n",
       "  0.849747896194458,\n",
       "  0.8514285683631897,\n",
       "  0.8494117856025696,\n",
       "  0.8515966534614563,\n",
       "  0.849747896194458,\n",
       "  0.8510924577713013,\n",
       "  0.8519327640533447,\n",
       "  0.8512604832649231,\n",
       "  0.8519327640533447,\n",
       "  0.8524369597434998,\n",
       "  0.8512604832649231,\n",
       "  0.8514285683631897,\n",
       "  0.8524369597434998,\n",
       "  0.850252091884613,\n",
       "  0.8524369597434998,\n",
       "  0.8519327640533447,\n",
       "  0.8510924577713013,\n",
       "  0.8519327640533447,\n",
       "  0.8524369597434998,\n",
       "  0.8531092405319214,\n",
       "  0.8526050448417664,\n",
       "  0.8522689342498779,\n",
       "  0.8541176319122314,\n",
       "  0.8489075899124146,\n",
       "  0.8557983040809631,\n",
       "  0.853277325630188,\n",
       "  0.8524369597434998,\n",
       "  0.8509243726730347,\n",
       "  0.8521008491516113,\n",
       "  0.8499159812927246,\n",
       "  0.8544538021087646,\n",
       "  0.8522689342498779,\n",
       "  0.8509243726730347,\n",
       "  0.8531092405319214,\n",
       "  0.8519327640533447,\n",
       "  0.8519327640533447,\n",
       "  0.8526050448417664,\n",
       "  0.8534453511238098,\n",
       "  0.853277325630188,\n",
       "  0.8529411554336548,\n",
       "  0.853781521320343,\n",
       "  0.8531092405319214,\n",
       "  0.8507562875747681,\n",
       "  0.8514285683631897,\n",
       "  0.8514285683631897,\n",
       "  0.852773129940033,\n",
       "  0.8536134362220764,\n",
       "  0.8529411554336548,\n",
       "  0.8526050448417664,\n",
       "  0.852773129940033,\n",
       "  0.8556302785873413,\n",
       "  0.8522689342498779,\n",
       "  0.8524369597434998,\n",
       "  0.8524369597434998,\n",
       "  0.853781521320343,\n",
       "  0.8526050448417664,\n",
       "  0.852773129940033,\n",
       "  0.8536134362220764,\n",
       "  0.8531092405319214,\n",
       "  0.8544538021087646,\n",
       "  0.853781521320343,\n",
       "  0.854285717010498,\n",
       "  0.8536134362220764,\n",
       "  0.853277325630188,\n",
       "  0.8546218276023865,\n",
       "  0.8534453511238098,\n",
       "  0.8531092405319214,\n",
       "  0.8522689342498779,\n",
       "  0.8512604832649231,\n",
       "  0.8531092405319214,\n",
       "  0.8529411554336548,\n",
       "  0.852773129940033,\n",
       "  0.8524369597434998,\n",
       "  0.8500840067863464,\n",
       "  0.8515966534614563,\n",
       "  0.852773129940033,\n",
       "  0.854285717010498,\n",
       "  0.8522689342498779,\n",
       "  0.8531092405319214,\n",
       "  0.8539496064186096,\n",
       "  0.8536134362220764,\n",
       "  0.8526050448417664,\n",
       "  0.8547899127006531,\n",
       "  0.8541176319122314,\n",
       "  0.8541176319122314,\n",
       "  0.8539496064186096,\n",
       "  0.853781521320343,\n",
       "  0.8551260232925415,\n",
       "  0.8524369597434998,\n",
       "  0.8517646789550781,\n",
       "  0.8521008491516113,\n",
       "  0.8529411554336548,\n",
       "  0.853277325630188,\n",
       "  0.8515966534614563,\n",
       "  0.8522689342498779,\n",
       "  0.8526050448417664,\n",
       "  0.8534453511238098,\n",
       "  0.852773129940033,\n",
       "  0.8531092405319214,\n",
       "  0.853277325630188,\n",
       "  0.8510924577713013,\n",
       "  0.853277325630188,\n",
       "  0.8549579977989197,\n",
       "  0.8541176319122314,\n",
       "  0.853277325630188,\n",
       "  0.8539496064186096,\n",
       "  0.8544538021087646,\n",
       "  0.854285717010498,\n",
       "  0.8526050448417664,\n",
       "  0.8546218276023865,\n",
       "  0.8549579977989197,\n",
       "  0.8519327640533447,\n",
       "  0.8541176319122314,\n",
       "  0.852773129940033,\n",
       "  0.8563024997711182,\n",
       "  0.8547899127006531,\n",
       "  0.8539496064186096,\n",
       "  0.8549579977989197,\n",
       "  0.854285717010498,\n",
       "  0.8529411554336548,\n",
       "  0.853277325630188,\n",
       "  0.8552941083908081,\n",
       "  0.8547899127006531,\n",
       "  0.8526050448417664,\n",
       "  0.8529411554336548,\n",
       "  0.853277325630188,\n",
       "  0.852773129940033,\n",
       "  0.853781521320343,\n",
       "  0.8544538021087646,\n",
       "  0.8536134362220764,\n",
       "  0.8522689342498779,\n",
       "  0.853277325630188,\n",
       "  0.8517646789550781,\n",
       "  0.8531092405319214,\n",
       "  0.8526050448417664,\n",
       "  0.854285717010498,\n",
       "  0.8529411554336548,\n",
       "  0.8515966534614563,\n",
       "  0.853277325630188,\n",
       "  0.853781521320343,\n",
       "  0.8541176319122314,\n",
       "  0.8526050448417664,\n",
       "  0.8546218276023865,\n",
       "  0.8539496064186096,\n",
       "  0.8539496064186096,\n",
       "  0.8547899127006531,\n",
       "  0.853781521320343,\n",
       "  0.853781521320343,\n",
       "  0.8541176319122314,\n",
       "  0.8541176319122314,\n",
       "  0.8515966534614563,\n",
       "  0.8531092405319214,\n",
       "  0.8536134362220764,\n",
       "  0.8515966534614563,\n",
       "  0.8517646789550781,\n",
       "  0.8531092405319214,\n",
       "  0.8534453511238098,\n",
       "  0.8547899127006531,\n",
       "  0.8526050448417664,\n",
       "  0.853277325630188,\n",
       "  0.8557983040809631,\n",
       "  0.8536134362220764,\n",
       "  0.8556302785873413,\n",
       "  0.8536134362220764,\n",
       "  0.8544538021087646,\n",
       "  0.8529411554336548,\n",
       "  0.8559663891792297,\n",
       "  0.853781521320343,\n",
       "  0.8522689342498779,\n",
       "  0.8534453511238098,\n",
       "  0.8544538021087646,\n",
       "  0.8544538021087646,\n",
       "  0.8529411554336548,\n",
       "  0.8549579977989197,\n",
       "  0.8546218276023865,\n",
       "  0.8551260232925415,\n",
       "  0.8544538021087646,\n",
       "  0.8551260232925415,\n",
       "  0.8549579977989197,\n",
       "  0.8551260232925415,\n",
       "  0.853277325630188,\n",
       "  0.8515966534614563,\n",
       "  0.8552941083908081,\n",
       "  0.852773129940033,\n",
       "  0.8519327640533447,\n",
       "  0.853781521320343,\n",
       "  0.8536134362220764,\n",
       "  0.8544538021087646,\n",
       "  0.8544538021087646,\n",
       "  0.8536134362220764,\n",
       "  0.8541176319122314,\n",
       "  0.8539496064186096],\n",
       " 'val_loss': [0.47571858763694763,\n",
       "  0.47420036792755127,\n",
       "  0.4690781235694885,\n",
       "  0.4680642783641815,\n",
       "  0.46247076988220215,\n",
       "  0.45901191234588623,\n",
       "  0.46132099628448486,\n",
       "  0.45692652463912964,\n",
       "  0.44809088110923767,\n",
       "  0.4459679424762726,\n",
       "  0.44660684466362,\n",
       "  0.4402989447116852,\n",
       "  0.43773123621940613,\n",
       "  0.4350522756576538,\n",
       "  0.4344328045845032,\n",
       "  0.43380022048950195,\n",
       "  0.4397774934768677,\n",
       "  0.427687406539917,\n",
       "  0.4299498200416565,\n",
       "  0.4293821454048157,\n",
       "  0.43481945991516113,\n",
       "  0.43045714497566223,\n",
       "  0.43354472517967224,\n",
       "  0.42481082677841187,\n",
       "  0.4367578327655792,\n",
       "  0.42098507285118103,\n",
       "  0.44296523928642273,\n",
       "  0.4259190261363983,\n",
       "  0.4196523427963257,\n",
       "  0.42398592829704285,\n",
       "  0.4152798652648926,\n",
       "  0.41455790400505066,\n",
       "  0.4268367886543274,\n",
       "  0.41582798957824707,\n",
       "  0.4141143560409546,\n",
       "  0.41664624214172363,\n",
       "  0.41209354996681213,\n",
       "  0.4214569628238678,\n",
       "  0.41398414969444275,\n",
       "  0.41407668590545654,\n",
       "  0.4120187759399414,\n",
       "  0.42813560366630554,\n",
       "  0.41177839040756226,\n",
       "  0.4187357425689697,\n",
       "  0.4107005000114441,\n",
       "  0.43158191442489624,\n",
       "  0.4138217270374298,\n",
       "  0.41254904866218567,\n",
       "  0.41880205273628235,\n",
       "  0.42659473419189453,\n",
       "  0.40896737575531006,\n",
       "  0.4198170304298401,\n",
       "  0.410478413105011,\n",
       "  0.4106025695800781,\n",
       "  0.4097632169723511,\n",
       "  0.40857577323913574,\n",
       "  0.4128311574459076,\n",
       "  0.4161396920681,\n",
       "  0.41494107246398926,\n",
       "  0.4090041220188141,\n",
       "  0.4091320335865021,\n",
       "  0.4149230718612671,\n",
       "  0.4132830798625946,\n",
       "  0.41327396035194397,\n",
       "  0.4099441468715668,\n",
       "  0.42684951424598694,\n",
       "  0.41316691040992737,\n",
       "  0.42094314098358154,\n",
       "  0.4152195155620575,\n",
       "  0.4120617210865021,\n",
       "  0.41394826769828796,\n",
       "  0.41767004132270813,\n",
       "  0.41764628887176514,\n",
       "  0.41376474499702454,\n",
       "  0.41406455636024475,\n",
       "  0.4137803614139557,\n",
       "  0.4111591577529907,\n",
       "  0.4065590798854828,\n",
       "  0.42206645011901855,\n",
       "  0.40655073523521423,\n",
       "  0.41889074444770813,\n",
       "  0.4100567400455475,\n",
       "  0.41137754917144775,\n",
       "  0.4068390130996704,\n",
       "  0.4056122303009033,\n",
       "  0.4140678644180298,\n",
       "  0.4065035283565521,\n",
       "  0.41374170780181885,\n",
       "  0.40574583411216736,\n",
       "  0.4067429006099701,\n",
       "  0.42142510414123535,\n",
       "  0.4053953289985657,\n",
       "  0.40648382902145386,\n",
       "  0.431519091129303,\n",
       "  0.41792193055152893,\n",
       "  0.41037771105766296,\n",
       "  0.41371193528175354,\n",
       "  0.40826767683029175,\n",
       "  0.4114600718021393,\n",
       "  0.4165480434894562,\n",
       "  0.4230414032936096,\n",
       "  0.4185989797115326,\n",
       "  0.4075562655925751,\n",
       "  0.41377490758895874,\n",
       "  0.4108010530471802,\n",
       "  0.4149716794490814,\n",
       "  0.4051966667175293,\n",
       "  0.4315071702003479,\n",
       "  0.4095342457294464,\n",
       "  0.4062821865081787,\n",
       "  0.4127204120159149,\n",
       "  0.4117870628833771,\n",
       "  0.4226134419441223,\n",
       "  0.4056081175804138,\n",
       "  0.42577865719795227,\n",
       "  0.4046567976474762,\n",
       "  0.40949589014053345,\n",
       "  0.41568630933761597,\n",
       "  0.4039510488510132,\n",
       "  0.40461277961730957,\n",
       "  0.403307169675827,\n",
       "  0.40954849123954773,\n",
       "  0.40556254982948303,\n",
       "  0.40455618500709534,\n",
       "  0.40547263622283936,\n",
       "  0.4150703549385071,\n",
       "  0.4212200343608856,\n",
       "  0.4024098217487335,\n",
       "  0.4149337112903595,\n",
       "  0.4059610664844513,\n",
       "  0.40455517172813416,\n",
       "  0.4018454849720001,\n",
       "  0.41066446900367737,\n",
       "  0.40183225274086,\n",
       "  0.40290817618370056,\n",
       "  0.40999728441238403,\n",
       "  0.41474634408950806,\n",
       "  0.4076838195323944,\n",
       "  0.40561139583587646,\n",
       "  0.40249618887901306,\n",
       "  0.40660154819488525,\n",
       "  0.4010999798774719,\n",
       "  0.40387341380119324,\n",
       "  0.3994317054748535,\n",
       "  0.40019235014915466,\n",
       "  0.3981574475765228,\n",
       "  0.3963041603565216,\n",
       "  0.40377870202064514,\n",
       "  0.40795403718948364,\n",
       "  0.3974926471710205,\n",
       "  0.40145230293273926,\n",
       "  0.39613980054855347,\n",
       "  0.4002409279346466,\n",
       "  0.39824599027633667,\n",
       "  0.4019638001918793,\n",
       "  0.40186595916748047,\n",
       "  0.40483951568603516,\n",
       "  0.3943250775337219,\n",
       "  0.3969520032405853,\n",
       "  0.40883252024650574,\n",
       "  0.39268288016319275,\n",
       "  0.41385942697525024,\n",
       "  0.393886536359787,\n",
       "  0.401420921087265,\n",
       "  0.3908919394016266,\n",
       "  0.3955605626106262,\n",
       "  0.42084071040153503,\n",
       "  0.3942701518535614,\n",
       "  0.3897709548473358,\n",
       "  0.39062726497650146,\n",
       "  0.3914733827114105,\n",
       "  0.406467080116272,\n",
       "  0.38942715525627136,\n",
       "  0.39347517490386963,\n",
       "  0.38931804895401,\n",
       "  0.3878346085548401,\n",
       "  0.40096378326416016,\n",
       "  0.39011895656585693,\n",
       "  0.38534244894981384,\n",
       "  0.39859864115715027,\n",
       "  0.39083173871040344,\n",
       "  0.3882787525653839,\n",
       "  0.38837647438049316,\n",
       "  0.39236316084861755,\n",
       "  0.39643484354019165,\n",
       "  0.3873915374279022,\n",
       "  0.38475242257118225,\n",
       "  0.3838898539543152,\n",
       "  0.3890339434146881,\n",
       "  0.3913685083389282,\n",
       "  0.38261592388153076,\n",
       "  0.38176190853118896,\n",
       "  0.38595664501190186,\n",
       "  0.38148632645606995,\n",
       "  0.3810558319091797,\n",
       "  0.3851849138736725,\n",
       "  0.3925980031490326,\n",
       "  0.39078107476234436,\n",
       "  0.38086116313934326,\n",
       "  0.3797396123409271,\n",
       "  0.37798547744750977,\n",
       "  0.3920842409133911,\n",
       "  0.3813283145427704,\n",
       "  0.3884376883506775,\n",
       "  0.38421759009361267,\n",
       "  0.378718763589859,\n",
       "  0.3770005404949188,\n",
       "  0.3844798803329468,\n",
       "  0.3747388422489166,\n",
       "  0.38001006841659546,\n",
       "  0.3816492557525635,\n",
       "  0.3767109215259552,\n",
       "  0.37503552436828613,\n",
       "  0.3744833171367645,\n",
       "  0.37693390250205994,\n",
       "  0.3744809925556183,\n",
       "  0.3765196204185486,\n",
       "  0.3726854920387268,\n",
       "  0.3813263475894928,\n",
       "  0.39116114377975464,\n",
       "  0.37467220425605774,\n",
       "  0.3728513717651367,\n",
       "  0.3722088038921356,\n",
       "  0.3784206211566925,\n",
       "  0.3771989643573761,\n",
       "  0.3755285143852234,\n",
       "  0.3700914680957794,\n",
       "  0.3790474832057953,\n",
       "  0.3709620237350464,\n",
       "  0.3746386766433716,\n",
       "  0.37581610679626465,\n",
       "  0.36805930733680725,\n",
       "  0.36768507957458496,\n",
       "  0.36895281076431274,\n",
       "  0.3708505928516388,\n",
       "  0.3690699338912964,\n",
       "  0.37033990025520325,\n",
       "  0.36617958545684814,\n",
       "  0.36606380343437195,\n",
       "  0.3704981803894043,\n",
       "  0.3704366385936737,\n",
       "  0.3680375814437866,\n",
       "  0.3707805275917053,\n",
       "  0.3655361533164978,\n",
       "  0.3667294383049011,\n",
       "  0.3695242404937744,\n",
       "  0.3759523034095764,\n",
       "  0.364496648311615,\n",
       "  0.38166144490242004,\n",
       "  0.367485374212265,\n",
       "  0.3768090009689331,\n",
       "  0.36471420526504517,\n",
       "  0.37537771463394165,\n",
       "  0.3749403655529022,\n",
       "  0.3681226670742035,\n",
       "  0.3631076216697693,\n",
       "  0.37255996465682983,\n",
       "  0.3853221535682678,\n",
       "  0.3621978759765625,\n",
       "  0.3637475073337555,\n",
       "  0.36365795135498047,\n",
       "  0.39944398403167725,\n",
       "  0.36352071166038513,\n",
       "  0.3702433109283447,\n",
       "  0.39548030495643616,\n",
       "  0.3705039918422699,\n",
       "  0.37007543444633484,\n",
       "  0.36238235235214233,\n",
       "  0.38042354583740234,\n",
       "  0.38084495067596436,\n",
       "  0.3693920075893402,\n",
       "  0.37083515524864197,\n",
       "  0.3716834485530853,\n",
       "  0.3636575937271118,\n",
       "  0.369223952293396,\n",
       "  0.39054250717163086,\n",
       "  0.41525736451148987,\n",
       "  0.3696673512458801,\n",
       "  0.369626522064209,\n",
       "  0.36412152647972107,\n",
       "  0.36881589889526367,\n",
       "  0.3691704273223877,\n",
       "  0.36517977714538574,\n",
       "  0.41962751746177673,\n",
       "  0.38246670365333557,\n",
       "  0.36748751997947693,\n",
       "  0.41474422812461853,\n",
       "  0.37259119749069214,\n",
       "  0.36752331256866455,\n",
       "  0.41725730895996094,\n",
       "  0.3691454827785492,\n",
       "  0.3895280957221985,\n",
       "  0.36087873578071594,\n",
       "  0.390624463558197,\n",
       "  0.3665006458759308,\n",
       "  0.38710644841194153,\n",
       "  0.38244858384132385,\n",
       "  0.3941444158554077,\n",
       "  0.37317657470703125,\n",
       "  0.39200422167778015,\n",
       "  0.37113428115844727,\n",
       "  0.3598574697971344,\n",
       "  0.36423757672309875,\n",
       "  0.37507620453834534,\n",
       "  0.3694116473197937,\n",
       "  0.36856523156166077,\n",
       "  0.3598068654537201,\n",
       "  0.359386682510376,\n",
       "  0.3885517120361328,\n",
       "  0.36062395572662354,\n",
       "  0.3676948845386505,\n",
       "  0.36650294065475464,\n",
       "  0.3593064546585083,\n",
       "  0.3770493268966675,\n",
       "  0.359151691198349,\n",
       "  0.43866729736328125,\n",
       "  0.36246609687805176,\n",
       "  0.3728519678115845,\n",
       "  0.35892677307128906,\n",
       "  0.39381080865859985,\n",
       "  0.35704687237739563,\n",
       "  0.38767412304878235,\n",
       "  0.35642415285110474,\n",
       "  0.38664448261260986,\n",
       "  0.386567622423172,\n",
       "  0.41114166378974915,\n",
       "  0.36209455132484436,\n",
       "  0.3779860734939575,\n",
       "  0.43399369716644287,\n",
       "  0.3622010052204132,\n",
       "  0.3609151244163513,\n",
       "  0.3647333085536957,\n",
       "  0.37659406661987305,\n",
       "  0.37610167264938354,\n",
       "  0.37331247329711914,\n",
       "  0.35801637172698975,\n",
       "  0.38099950551986694,\n",
       "  0.3571995794773102,\n",
       "  0.3560120463371277,\n",
       "  0.35509806871414185,\n",
       "  0.3883151710033417,\n",
       "  0.3958861529827118,\n",
       "  0.36344587802886963,\n",
       "  0.3843153715133667,\n",
       "  0.36742401123046875,\n",
       "  0.3561238646507263,\n",
       "  0.3558141887187958,\n",
       "  0.35443365573883057,\n",
       "  0.3676935136318207,\n",
       "  0.3560532033443451,\n",
       "  0.3544726073741913,\n",
       "  0.35311079025268555,\n",
       "  0.37025704979896545,\n",
       "  0.35662487149238586,\n",
       "  0.38329261541366577,\n",
       "  0.3664618730545044,\n",
       "  0.3746304512023926,\n",
       "  0.3537452518939972,\n",
       "  0.3624248206615448,\n",
       "  0.35915786027908325,\n",
       "  0.3551553189754486,\n",
       "  0.36939728260040283,\n",
       "  0.374610036611557,\n",
       "  0.35921594500541687,\n",
       "  0.3543244004249573,\n",
       "  0.376669704914093,\n",
       "  0.35672274231910706,\n",
       "  0.3554692268371582,\n",
       "  0.3607155680656433,\n",
       "  0.3710482120513916,\n",
       "  0.35733309388160706,\n",
       "  0.38001686334609985,\n",
       "  0.38483190536499023,\n",
       "  0.3968743085861206,\n",
       "  0.35508474707603455,\n",
       "  0.3638658821582794,\n",
       "  0.3851870000362396,\n",
       "  0.3524104654788971,\n",
       "  0.37672021985054016,\n",
       "  0.3535672128200531,\n",
       "  0.3588525354862213,\n",
       "  0.37435007095336914,\n",
       "  0.3659990727901459,\n",
       "  0.3553171455860138,\n",
       "  0.3594858944416046,\n",
       "  0.35720759630203247,\n",
       "  0.3654382824897766,\n",
       "  0.35840556025505066,\n",
       "  0.3542759120464325,\n",
       "  0.35729801654815674,\n",
       "  0.3592226505279541,\n",
       "  0.3553289473056793,\n",
       "  0.42091843485832214,\n",
       "  0.3597884178161621,\n",
       "  0.35414478182792664,\n",
       "  0.3582005500793457,\n",
       "  0.3988252580165863,\n",
       "  0.3837483823299408,\n",
       "  0.37394773960113525,\n",
       "  0.37233400344848633,\n",
       "  0.35641419887542725,\n",
       "  0.38397032022476196,\n",
       "  0.3732777535915375,\n",
       "  0.3619284927845001,\n",
       "  0.3575606644153595,\n",
       "  0.35315632820129395,\n",
       "  0.3558422923088074,\n",
       "  0.35969865322113037,\n",
       "  0.3629888594150543,\n",
       "  0.39651525020599365,\n",
       "  0.36457696557044983,\n",
       "  0.3538655638694763,\n",
       "  0.3537720739841461,\n",
       "  0.3667829632759094,\n",
       "  0.35739263892173767,\n",
       "  0.35463836789131165,\n",
       "  0.41823816299438477,\n",
       "  0.35745903849601746,\n",
       "  0.39922964572906494,\n",
       "  0.3746330738067627,\n",
       "  0.3542225658893585,\n",
       "  0.3729235529899597,\n",
       "  0.36390507221221924,\n",
       "  0.3828342854976654,\n",
       "  0.38344648480415344,\n",
       "  0.3533272445201874,\n",
       "  0.36529257893562317,\n",
       "  0.35489824414253235,\n",
       "  0.37136906385421753,\n",
       "  0.35626140236854553,\n",
       "  0.4060615599155426,\n",
       "  0.3565846383571625,\n",
       "  0.3830728530883789,\n",
       "  0.35444822907447815,\n",
       "  0.36115753650665283,\n",
       "  0.364372193813324,\n",
       "  0.3720046281814575,\n",
       "  0.3721117377281189,\n",
       "  0.37177199125289917,\n",
       "  0.3981626629829407,\n",
       "  0.4023309051990509,\n",
       "  0.4109407365322113,\n",
       "  0.3706536293029785,\n",
       "  0.371774286031723,\n",
       "  0.371286004781723,\n",
       "  0.3635837435722351,\n",
       "  0.35414478182792664,\n",
       "  0.38392484188079834,\n",
       "  0.37089189887046814,\n",
       "  0.3719360828399658,\n",
       "  0.3640904128551483,\n",
       "  0.37665417790412903,\n",
       "  0.3572896420955658,\n",
       "  0.36840277910232544,\n",
       "  0.38981205224990845,\n",
       "  0.37257108092308044,\n",
       "  0.36840495467185974,\n",
       "  0.3702932298183441,\n",
       "  0.3703369200229645,\n",
       "  0.36037519574165344,\n",
       "  0.35938915610313416,\n",
       "  0.3736558258533478,\n",
       "  0.3912368714809418,\n",
       "  0.3833891749382019,\n",
       "  0.41726651787757874,\n",
       "  0.3927418887615204,\n",
       "  0.3783623278141022,\n",
       "  0.35474398732185364,\n",
       "  0.3550504148006439,\n",
       "  0.3897906243801117,\n",
       "  0.3715380132198334,\n",
       "  0.37260061502456665,\n",
       "  0.37465107440948486,\n",
       "  0.36204665899276733,\n",
       "  0.3584509789943695,\n",
       "  0.35341212153434753,\n",
       "  0.38333824276924133,\n",
       "  0.41958093643188477,\n",
       "  0.36740246415138245,\n",
       "  0.383645623922348,\n",
       "  0.44855642318725586,\n",
       "  0.3693661391735077,\n",
       "  0.36451834440231323,\n",
       "  0.3725123107433319,\n",
       "  0.40226149559020996,\n",
       "  0.3527388870716095,\n",
       "  0.3660781979560852,\n",
       "  0.37066224217414856,\n",
       "  0.3936157524585724,\n",
       "  0.3715653121471405,\n",
       "  0.35610154271125793,\n",
       "  0.3804260194301605,\n",
       "  0.40319734811782837,\n",
       "  0.37183550000190735,\n",
       "  0.3733494281768799,\n",
       "  0.3549289405345917,\n",
       "  0.37050554156303406,\n",
       "  0.4090769588947296,\n",
       "  0.3551485538482666,\n",
       "  0.3672742545604706,\n",
       "  0.369182288646698,\n",
       "  0.3711561858654022,\n",
       "  0.37285828590393066,\n",
       "  0.37161001563072205,\n",
       "  0.4414726197719574,\n",
       "  0.3704209327697754,\n",
       "  0.3868875503540039,\n",
       "  0.40075182914733887,\n",
       "  0.3664167821407318,\n",
       "  0.3856336176395416,\n",
       "  0.37340232729911804,\n",
       "  0.3952767848968506,\n",
       "  0.3712370991706848,\n",
       "  0.429456889629364,\n",
       "  0.3810386657714844,\n",
       "  0.3719751536846161,\n",
       "  0.41022148728370667,\n",
       "  0.3633584678173065,\n",
       "  0.3838246762752533,\n",
       "  0.37516549229621887,\n",
       "  0.36235368251800537,\n",
       "  0.3895147144794464,\n",
       "  0.3687080442905426,\n",
       "  0.38669314980506897,\n",
       "  0.3618423342704773,\n",
       "  0.40738606452941895,\n",
       "  0.37165263295173645,\n",
       "  0.37169361114501953,\n",
       "  0.3623058497905731,\n",
       "  0.4153774082660675,\n",
       "  0.38244539499282837,\n",
       "  0.45193949341773987,\n",
       "  0.441830575466156,\n",
       "  0.3738376200199127,\n",
       "  0.3905586004257202,\n",
       "  0.3926352262496948,\n",
       "  0.3968285918235779,\n",
       "  0.3577212393283844,\n",
       "  0.3635968267917633,\n",
       "  0.41241177916526794,\n",
       "  0.39516597986221313,\n",
       "  0.4334547817707062,\n",
       "  0.35401809215545654,\n",
       "  0.3771688640117645,\n",
       "  0.3735959827899933,\n",
       "  0.3785723149776459,\n",
       "  0.3832942545413971,\n",
       "  0.3676826059818268,\n",
       "  0.4250446557998657,\n",
       "  0.3691430389881134,\n",
       "  0.3730764091014862,\n",
       "  0.3965025842189789,\n",
       "  0.39282000064849854,\n",
       "  0.38245251774787903,\n",
       "  0.415724515914917,\n",
       "  0.3644990622997284,\n",
       "  0.3650641143321991,\n",
       "  0.36335667967796326,\n",
       "  0.3845273554325104,\n",
       "  0.3896801173686981,\n",
       "  0.36657655239105225,\n",
       "  0.3858565092086792,\n",
       "  0.38710832595825195,\n",
       "  0.3778786361217499,\n",
       "  0.38146063685417175,\n",
       "  0.3830918073654175,\n",
       "  0.3770463764667511,\n",
       "  0.39097318053245544,\n",
       "  0.37408027052879333,\n",
       "  0.39337390661239624,\n",
       "  0.3913075625896454,\n",
       "  0.36769863963127136,\n",
       "  0.36675527691841125,\n",
       "  0.3861630856990814,\n",
       "  0.37472960352897644,\n",
       "  0.3893677294254303,\n",
       "  0.3775138854980469,\n",
       "  0.4033789038658142,\n",
       "  0.3762166500091553,\n",
       "  0.38584840297698975,\n",
       "  0.3798086941242218,\n",
       "  0.37241309881210327,\n",
       "  0.4192686378955841,\n",
       "  0.3647211790084839,\n",
       "  0.3661032021045685,\n",
       "  0.36892688274383545,\n",
       "  0.43699830770492554,\n",
       "  0.38980773091316223,\n",
       "  0.4001666307449341,\n",
       "  0.38994041085243225,\n",
       "  0.38331863284111023,\n",
       "  0.3901525139808655,\n",
       "  0.36525335907936096,\n",
       "  0.3833158612251282,\n",
       "  0.37203100323677063,\n",
       "  0.3931402564048767,\n",
       "  0.3851749300956726,\n",
       "  0.39918947219848633,\n",
       "  0.39074552059173584,\n",
       "  0.3913240134716034],\n",
       " 'val_accuracy': [0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8171428442001343,\n",
       "  0.8180952668190002,\n",
       "  0.8190476298332214,\n",
       "  0.8171428442001343,\n",
       "  0.8180952668190002,\n",
       "  0.8171428442001343,\n",
       "  0.8180952668190002,\n",
       "  0.8171428442001343,\n",
       "  0.8180952668190002,\n",
       "  0.8171428442001343,\n",
       "  0.8171428442001343,\n",
       "  0.8180952668190002,\n",
       "  0.8171428442001343,\n",
       "  0.8171428442001343,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8171428442001343,\n",
       "  0.8190476298332214,\n",
       "  0.8180952668190002,\n",
       "  0.8171428442001343,\n",
       "  0.8171428442001343,\n",
       "  0.8199999928474426,\n",
       "  0.8171428442001343,\n",
       "  0.8171428442001343,\n",
       "  0.8171428442001343,\n",
       "  0.8190476298332214,\n",
       "  0.8171428442001343,\n",
       "  0.8199999928474426,\n",
       "  0.8161904811859131,\n",
       "  0.8161904811859131,\n",
       "  0.8171428442001343,\n",
       "  0.8171428442001343,\n",
       "  0.8152381181716919,\n",
       "  0.8190476298332214,\n",
       "  0.8152381181716919,\n",
       "  0.8161904811859131,\n",
       "  0.8161904811859131,\n",
       "  0.8190476298332214,\n",
       "  0.8190476298332214,\n",
       "  0.8171428442001343,\n",
       "  0.8171428442001343,\n",
       "  0.8152381181716919,\n",
       "  0.8190476298332214,\n",
       "  0.8190476298332214,\n",
       "  0.8190476298332214,\n",
       "  0.8180952668190002,\n",
       "  0.8199999928474426,\n",
       "  0.8190476298332214,\n",
       "  0.8171428442001343,\n",
       "  0.8180952668190002,\n",
       "  0.8180952668190002,\n",
       "  0.8161904811859131,\n",
       "  0.8190476298332214,\n",
       "  0.8171428442001343,\n",
       "  0.8171428442001343,\n",
       "  0.8161904811859131,\n",
       "  0.8152381181716919,\n",
       "  0.8171428442001343,\n",
       "  0.8190476298332214,\n",
       "  0.8152381181716919,\n",
       "  0.8180952668190002,\n",
       "  0.8152381181716919,\n",
       "  0.8180952668190002,\n",
       "  0.8152381181716919,\n",
       "  0.8161904811859131,\n",
       "  0.8199999928474426,\n",
       "  0.8180952668190002,\n",
       "  0.8171428442001343,\n",
       "  0.8171428442001343,\n",
       "  0.8161904811859131,\n",
       "  0.8161904811859131,\n",
       "  0.8209523558616638,\n",
       "  0.8199999928474426,\n",
       "  0.8209523558616638,\n",
       "  0.8171428442001343,\n",
       "  0.8152381181716919,\n",
       "  0.8209523558616638,\n",
       "  0.8199999928474426,\n",
       "  0.8199999928474426,\n",
       "  0.8152381181716919,\n",
       "  0.8171428442001343,\n",
       "  0.8152381181716919,\n",
       "  0.8152381181716919,\n",
       "  0.8152381181716919,\n",
       "  0.8180952668190002,\n",
       "  0.8199999928474426,\n",
       "  0.8161904811859131,\n",
       "  0.8171428442001343,\n",
       "  0.8199999928474426,\n",
       "  0.8152381181716919,\n",
       "  0.8199999928474426,\n",
       "  0.8180952668190002,\n",
       "  0.8190476298332214,\n",
       "  0.8199999928474426,\n",
       "  0.8171428442001343,\n",
       "  0.8209523558616638,\n",
       "  0.8180952668190002,\n",
       "  0.8209523558616638,\n",
       "  0.8190476298332214,\n",
       "  0.8209523558616638,\n",
       "  0.8171428442001343,\n",
       "  0.8219047784805298,\n",
       "  0.822857141494751,\n",
       "  0.8190476298332214,\n",
       "  0.822857141494751,\n",
       "  0.8199999928474426,\n",
       "  0.8219047784805298,\n",
       "  0.8219047784805298,\n",
       "  0.8219047784805298,\n",
       "  0.8190476298332214,\n",
       "  0.8209523558616638,\n",
       "  0.8219047784805298,\n",
       "  0.8257142901420593,\n",
       "  0.8219047784805298,\n",
       "  0.822857141494751,\n",
       "  0.8247619271278381,\n",
       "  0.8219047784805298,\n",
       "  0.8199999928474426,\n",
       "  0.8238095045089722,\n",
       "  0.8219047784805298,\n",
       "  0.8266666531562805,\n",
       "  0.8180952668190002,\n",
       "  0.8190476298332214,\n",
       "  0.8257142901420593,\n",
       "  0.8276190757751465,\n",
       "  0.822857141494751,\n",
       "  0.8238095045089722,\n",
       "  0.8180952668190002,\n",
       "  0.8247619271278381,\n",
       "  0.8238095045089722,\n",
       "  0.8276190757751465,\n",
       "  0.8276190757751465,\n",
       "  0.8295238018035889,\n",
       "  0.8247619271278381,\n",
       "  0.8247619271278381,\n",
       "  0.8180952668190002,\n",
       "  0.8247619271278381,\n",
       "  0.8295238018035889,\n",
       "  0.8190476298332214,\n",
       "  0.8295238018035889,\n",
       "  0.8247619271278381,\n",
       "  0.8266666531562805,\n",
       "  0.831428587436676,\n",
       "  0.8276190757751465,\n",
       "  0.8247619271278381,\n",
       "  0.8266666531562805,\n",
       "  0.8276190757751465,\n",
       "  0.8323809504508972,\n",
       "  0.8199999928474426,\n",
       "  0.8295238018035889,\n",
       "  0.8266666531562805,\n",
       "  0.8257142901420593,\n",
       "  0.8323809504508972,\n",
       "  0.8295238018035889,\n",
       "  0.8285714387893677,\n",
       "  0.8352380990982056,\n",
       "  0.8304761648178101,\n",
       "  0.831428587436676,\n",
       "  0.831428587436676,\n",
       "  0.8304761648178101,\n",
       "  0.8323809504508972,\n",
       "  0.831428587436676,\n",
       "  0.831428587436676,\n",
       "  0.831428587436676,\n",
       "  0.831428587436676,\n",
       "  0.831428587436676,\n",
       "  0.8295238018035889,\n",
       "  0.831428587436676,\n",
       "  0.831428587436676,\n",
       "  0.8352380990982056,\n",
       "  0.8295238018035889,\n",
       "  0.8352380990982056,\n",
       "  0.8361904621124268,\n",
       "  0.8371428847312927,\n",
       "  0.831428587436676,\n",
       "  0.831428587436676,\n",
       "  0.8323809504508972,\n",
       "  0.8304761648178101,\n",
       "  0.831428587436676,\n",
       "  0.8371428847312927,\n",
       "  0.8333333134651184,\n",
       "  0.8304761648178101,\n",
       "  0.8333333134651184,\n",
       "  0.8380952477455139,\n",
       "  0.8352380990982056,\n",
       "  0.8295238018035889,\n",
       "  0.831428587436676,\n",
       "  0.8352380990982056,\n",
       "  0.8333333134651184,\n",
       "  0.8352380990982056,\n",
       "  0.8352380990982056,\n",
       "  0.8333333134651184,\n",
       "  0.8361904621124268,\n",
       "  0.8371428847312927,\n",
       "  0.8419047594070435,\n",
       "  0.8285714387893677,\n",
       "  0.8380952477455139,\n",
       "  0.8390476107597351,\n",
       "  0.8361904621124268,\n",
       "  0.8390476107597351,\n",
       "  0.8371428847312927,\n",
       "  0.8399999737739563,\n",
       "  0.8380952477455139,\n",
       "  0.8409523963928223,\n",
       "  0.8399999737739563,\n",
       "  0.8399999737739563,\n",
       "  0.8419047594070435,\n",
       "  0.8361904621124268,\n",
       "  0.8390476107597351,\n",
       "  0.8409523963928223,\n",
       "  0.8352380990982056,\n",
       "  0.8409523963928223,\n",
       "  0.8399999737739563,\n",
       "  0.8419047594070435,\n",
       "  0.8409523963928223,\n",
       "  0.8419047594070435,\n",
       "  0.8419047594070435,\n",
       "  0.8428571224212646,\n",
       "  0.8380952477455139,\n",
       "  0.8419047594070435,\n",
       "  0.8428571224212646,\n",
       "  0.8504762053489685,\n",
       "  0.8409523963928223,\n",
       "  0.845714271068573,\n",
       "  0.8485714197158813,\n",
       "  0.8438095450401306,\n",
       "  0.8409523963928223,\n",
       "  0.8447619080543518,\n",
       "  0.8419047594070435,\n",
       "  0.8504762053489685,\n",
       "  0.8523809313774109,\n",
       "  0.8476190567016602,\n",
       "  0.8485714197158813,\n",
       "  0.8447619080543518,\n",
       "  0.8495237827301025,\n",
       "  0.8485714197158813,\n",
       "  0.845714271068573,\n",
       "  0.8419047594070435,\n",
       "  0.8485714197158813,\n",
       "  0.8485714197158813,\n",
       "  0.8428571224212646,\n",
       "  0.8533333539962769,\n",
       "  0.8485714197158813,\n",
       "  0.8533333539962769,\n",
       "  0.8476190567016602,\n",
       "  0.8476190567016602,\n",
       "  0.8476190567016602,\n",
       "  0.8476190567016602,\n",
       "  0.846666693687439,\n",
       "  0.8533333539962769,\n",
       "  0.8514285683631897,\n",
       "  0.8476190567016602,\n",
       "  0.8438095450401306,\n",
       "  0.8504762053489685,\n",
       "  0.846666693687439,\n",
       "  0.8523809313774109,\n",
       "  0.8476190567016602,\n",
       "  0.8514285683631897,\n",
       "  0.8495237827301025,\n",
       "  0.8447619080543518,\n",
       "  0.8495237827301025,\n",
       "  0.8552380800247192,\n",
       "  0.845714271068573,\n",
       "  0.8485714197158813,\n",
       "  0.8476190567016602,\n",
       "  0.8447619080543518,\n",
       "  0.8485714197158813,\n",
       "  0.8495237827301025,\n",
       "  0.854285717010498,\n",
       "  0.845714271068573,\n",
       "  0.8514285683631897,\n",
       "  0.8485714197158813,\n",
       "  0.8485714197158813,\n",
       "  0.8495237827301025,\n",
       "  0.8523809313774109,\n",
       "  0.8504762053489685,\n",
       "  0.8504762053489685,\n",
       "  0.8504762053489685,\n",
       "  0.8533333539962769,\n",
       "  0.8523809313774109,\n",
       "  0.8514285683631897,\n",
       "  0.8485714197158813,\n",
       "  0.8533333539962769,\n",
       "  0.8504762053489685,\n",
       "  0.8495237827301025,\n",
       "  0.8523809313774109,\n",
       "  0.8504762053489685,\n",
       "  0.8495237827301025,\n",
       "  0.8504762053489685,\n",
       "  0.8504762053489685,\n",
       "  0.854285717010498,\n",
       "  0.845714271068573,\n",
       "  0.8561905026435852,\n",
       "  0.8552380800247192,\n",
       "  0.8495237827301025,\n",
       "  0.8514285683631897,\n",
       "  0.8514285683631897,\n",
       "  0.8514285683631897,\n",
       "  0.8533333539962769,\n",
       "  0.8514285683631897,\n",
       "  0.8561905026435852,\n",
       "  0.8504762053489685,\n",
       "  0.8561905026435852,\n",
       "  0.8523809313774109,\n",
       "  0.8504762053489685,\n",
       "  0.8571428656578064,\n",
       "  0.854285717010498,\n",
       "  0.8561905026435852,\n",
       "  0.8552380800247192,\n",
       "  0.8571428656578064,\n",
       "  0.8523809313774109,\n",
       "  0.8523809313774109,\n",
       "  0.8552380800247192,\n",
       "  0.854285717010498,\n",
       "  0.8552380800247192,\n",
       "  0.8571428656578064,\n",
       "  0.8533333539962769,\n",
       "  0.8533333539962769,\n",
       "  0.8533333539962769,\n",
       "  0.8552380800247192,\n",
       "  0.8561905026435852,\n",
       "  0.8552380800247192,\n",
       "  0.8571428656578064,\n",
       "  0.8571428656578064,\n",
       "  0.8552380800247192,\n",
       "  0.854285717010498,\n",
       "  0.8561905026435852,\n",
       "  0.8552380800247192,\n",
       "  0.854285717010498,\n",
       "  0.8552380800247192,\n",
       "  0.8561905026435852,\n",
       "  0.8561905026435852,\n",
       "  0.8514285683631897,\n",
       "  0.8561905026435852,\n",
       "  0.854285717010498,\n",
       "  0.8561905026435852,\n",
       "  0.8561905026435852,\n",
       "  0.8571428656578064,\n",
       "  0.8552380800247192,\n",
       "  0.8552380800247192,\n",
       "  0.854285717010498,\n",
       "  0.8533333539962769,\n",
       "  0.8533333539962769,\n",
       "  0.8533333539962769,\n",
       "  0.854285717010498,\n",
       "  0.8552380800247192,\n",
       "  0.8561905026435852,\n",
       "  0.8561905026435852,\n",
       "  0.8552380800247192,\n",
       "  0.8533333539962769,\n",
       "  0.8571428656578064,\n",
       "  0.854285717010498,\n",
       "  0.854285717010498,\n",
       "  0.8580952286720276,\n",
       "  0.8600000143051147,\n",
       "  0.8561905026435852,\n",
       "  0.8533333539962769,\n",
       "  0.8552380800247192,\n",
       "  0.8552380800247192,\n",
       "  0.8552380800247192,\n",
       "  0.854285717010498,\n",
       "  0.8580952286720276,\n",
       "  0.8571428656578064,\n",
       "  0.8590475916862488,\n",
       "  0.854285717010498,\n",
       "  0.8561905026435852,\n",
       "  0.8552380800247192,\n",
       "  0.8552380800247192,\n",
       "  0.854285717010498,\n",
       "  0.8571428656578064,\n",
       "  0.8571428656578064,\n",
       "  0.8580952286720276,\n",
       "  0.8514285683631897,\n",
       "  0.8571428656578064,\n",
       "  0.8552380800247192,\n",
       "  0.8561905026435852,\n",
       "  0.8590475916862488,\n",
       "  0.8561905026435852,\n",
       "  0.8609523773193359,\n",
       "  0.8561905026435852,\n",
       "  0.8571428656578064,\n",
       "  0.8561905026435852,\n",
       "  0.8571428656578064,\n",
       "  0.854285717010498,\n",
       "  0.8590475916862488,\n",
       "  0.8533333539962769,\n",
       "  0.8552380800247192,\n",
       "  0.8561905026435852,\n",
       "  0.8580952286720276,\n",
       "  0.8580952286720276,\n",
       "  0.8590475916862488,\n",
       "  0.8580952286720276,\n",
       "  0.854285717010498,\n",
       "  0.8590475916862488,\n",
       "  0.854285717010498,\n",
       "  0.854285717010498,\n",
       "  0.8590475916862488,\n",
       "  0.8561905026435852,\n",
       "  0.8590475916862488,\n",
       "  0.8571428656578064,\n",
       "  0.854285717010498,\n",
       "  0.8590475916862488,\n",
       "  0.8561905026435852,\n",
       "  0.8600000143051147,\n",
       "  0.8571428656578064,\n",
       "  0.8590475916862488,\n",
       "  0.854285717010498,\n",
       "  0.8600000143051147,\n",
       "  0.8571428656578064,\n",
       "  0.8600000143051147,\n",
       "  0.8571428656578064,\n",
       "  0.8571428656578064,\n",
       "  0.8561905026435852,\n",
       "  0.8561905026435852,\n",
       "  0.8552380800247192,\n",
       "  0.8552380800247192,\n",
       "  0.8590475916862488,\n",
       "  0.854285717010498,\n",
       "  0.8580952286720276,\n",
       "  0.8561905026435852,\n",
       "  0.8580952286720276,\n",
       "  0.8561905026435852,\n",
       "  0.8609523773193359,\n",
       "  0.8580952286720276,\n",
       "  0.8571428656578064,\n",
       "  0.8552380800247192,\n",
       "  0.8561905026435852,\n",
       "  0.8609523773193359,\n",
       "  0.8619047403335571,\n",
       "  0.8600000143051147,\n",
       "  0.8609523773193359,\n",
       "  0.8552380800247192,\n",
       "  0.8619047403335571,\n",
       "  0.8600000143051147,\n",
       "  0.8600000143051147,\n",
       "  0.8619047403335571,\n",
       "  0.8600000143051147,\n",
       "  0.8552380800247192,\n",
       "  0.8600000143051147,\n",
       "  0.8638095259666443,\n",
       "  0.8571428656578064,\n",
       "  0.8571428656578064,\n",
       "  0.8552380800247192,\n",
       "  0.8590475916862488,\n",
       "  0.8561905026435852,\n",
       "  0.854285717010498,\n",
       "  0.8619047403335571,\n",
       "  0.8561905026435852,\n",
       "  0.8552380800247192,\n",
       "  0.8590475916862488,\n",
       "  0.8561905026435852,\n",
       "  0.8580952286720276,\n",
       "  0.8552380800247192,\n",
       "  0.8514285683631897,\n",
       "  0.8590475916862488,\n",
       "  0.854285717010498,\n",
       "  0.8476190567016602,\n",
       "  0.8571428656578064,\n",
       "  0.8590475916862488,\n",
       "  0.8580952286720276,\n",
       "  0.8600000143051147,\n",
       "  0.8590475916862488,\n",
       "  0.8600000143051147,\n",
       "  0.8590475916862488,\n",
       "  0.8561905026435852,\n",
       "  0.8580952286720276,\n",
       "  0.8600000143051147,\n",
       "  0.8609523773193359,\n",
       "  0.8514285683631897,\n",
       "  0.8561905026435852,\n",
       "  0.8561905026435852,\n",
       "  0.8590475916862488,\n",
       "  0.8590475916862488,\n",
       "  0.8561905026435852,\n",
       "  0.8600000143051147,\n",
       "  0.8571428656578064,\n",
       "  0.8571428656578064,\n",
       "  0.8580952286720276,\n",
       "  0.8580952286720276,\n",
       "  0.8561905026435852,\n",
       "  0.8495237827301025,\n",
       "  0.8561905026435852,\n",
       "  0.8514285683631897,\n",
       "  0.8523809313774109,\n",
       "  0.8600000143051147,\n",
       "  0.8552380800247192,\n",
       "  0.8580952286720276,\n",
       "  0.8580952286720276,\n",
       "  0.8561905026435852,\n",
       "  0.8514285683631897,\n",
       "  0.8590475916862488,\n",
       "  0.8580952286720276,\n",
       "  0.8561905026435852,\n",
       "  0.8600000143051147,\n",
       "  0.854285717010498,\n",
       "  0.8590475916862488,\n",
       "  0.8580952286720276,\n",
       "  0.8561905026435852,\n",
       "  0.8600000143051147,\n",
       "  0.8609523773193359,\n",
       "  0.8590475916862488,\n",
       "  0.8600000143051147,\n",
       "  0.8571428656578064,\n",
       "  0.8580952286720276,\n",
       "  0.8619047403335571,\n",
       "  0.8609523773193359,\n",
       "  0.8561905026435852,\n",
       "  0.8495237827301025,\n",
       "  0.8495237827301025,\n",
       "  0.8600000143051147,\n",
       "  0.8571428656578064,\n",
       "  0.8571428656578064,\n",
       "  0.8495237827301025,\n",
       "  0.8590475916862488,\n",
       "  0.8590475916862488,\n",
       "  0.8580952286720276,\n",
       "  0.8600000143051147,\n",
       "  0.8485714197158813,\n",
       "  0.8580952286720276,\n",
       "  0.8600000143051147,\n",
       "  0.8600000143051147,\n",
       "  0.8609523773193359,\n",
       "  0.8552380800247192,\n",
       "  0.8600000143051147,\n",
       "  0.8495237827301025,\n",
       "  0.8619047403335571,\n",
       "  0.8580952286720276,\n",
       "  0.8561905026435852,\n",
       "  0.8590475916862488,\n",
       "  0.8552380800247192,\n",
       "  0.8571428656578064,\n",
       "  0.8590475916862488,\n",
       "  0.8590475916862488,\n",
       "  0.8600000143051147,\n",
       "  0.8533333539962769,\n",
       "  0.8619047403335571,\n",
       "  0.8609523773193359,\n",
       "  0.8580952286720276,\n",
       "  0.8580952286720276,\n",
       "  0.8580952286720276,\n",
       "  0.8561905026435852,\n",
       "  0.854285717010498,\n",
       "  0.8561905026435852,\n",
       "  0.8580952286720276,\n",
       "  0.8571428656578064,\n",
       "  0.8600000143051147,\n",
       "  0.8580952286720276,\n",
       "  0.8571428656578064,\n",
       "  0.8600000143051147,\n",
       "  0.8580952286720276,\n",
       "  0.8590475916862488,\n",
       "  0.8619047403335571,\n",
       "  0.8590475916862488,\n",
       "  0.8600000143051147,\n",
       "  0.8561905026435852,\n",
       "  0.8590475916862488,\n",
       "  0.8561905026435852,\n",
       "  0.8638095259666443,\n",
       "  0.8590475916862488,\n",
       "  0.8609523773193359,\n",
       "  0.8628571629524231,\n",
       "  0.8619047403335571,\n",
       "  0.8495237827301025,\n",
       "  0.8580952286720276,\n",
       "  0.8495237827301025,\n",
       "  0.8600000143051147,\n",
       "  0.8561905026435852,\n",
       "  0.8580952286720276,\n",
       "  0.8580952286720276,\n",
       "  0.8561905026435852,\n",
       "  0.8609523773193359,\n",
       "  0.8571428656578064,\n",
       "  0.8561905026435852,\n",
       "  0.8533333539962769,\n",
       "  0.8580952286720276,\n",
       "  0.8590475916862488]}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.511</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.509</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.506</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.503</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.400</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.398</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.407</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.402</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.405</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  accuracy  val_loss  val_accuracy\n",
       "0   0.511     0.794     0.476         0.818\n",
       "1   0.509     0.794     0.474         0.818\n",
       "2   0.506     0.794     0.469         0.818\n",
       "3   0.503     0.794     0.468         0.818\n",
       "4   0.500     0.794     0.462         0.818\n",
       "..    ...       ...       ...           ...\n",
       "595 0.400     0.854     0.393         0.857\n",
       "596 0.398     0.854     0.385         0.856\n",
       "597 0.407     0.854     0.399         0.853\n",
       "598 0.402     0.854     0.391         0.858\n",
       "599 0.405     0.854     0.391         0.859\n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Model\n",
    "\n",
    "- Plot the model history to observe the changing of metrics\n",
    "- Make prediction to see \"confusion matrix\" and \"classification report\"\n",
    "- Check ROC (Receiver Operating Curve) and AUC (Area Under Curve) for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss and val_loss values have been decreasing together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3982328772544861, 0.8536666631698608]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.2704512388417539 \n",
      "mae: 0.2685279234250387 \n",
      "mse: 0.11989858282326 \n",
      "rmse: 0.3462637474863056\n"
     ]
    }
   ],
   "source": [
    "eval_metric(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve, plot_precision_recall_curve, roc_auc_score, auc, roc_curve, average_precision_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_roc_curve(model, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with class_weigth\n",
    "\n",
    "Investigate how the \"class_weight\" hyper-parameter is used in a Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Model\n",
    "\n",
    "- Plot the model history to observe the changing of metrics\n",
    "- Make prediction to see \"confusion matrix\" and \"classification report\"\n",
    "- Check ROC (Receiver Operating Curve) and AUC (Area Under Curve) for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Different Methods to Develop The Model\n",
    "\n",
    "- Implement the following methods on model creating with \"class_weight\" parameter\n",
    "- Create and evaluate model for each method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase The Learning Rate and Observe The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Early Stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitor the \"val_loss\" as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitor the \"val_recall\" as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Model\n",
    "\n",
    "- Plot the model history to observe the changing of metrics\n",
    "- Make prediction to see \"confusion matrix\" and \"classification report\"\n",
    "- Check ROC (Receiver Operating Curve) and AUC (Area Under Curve) for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model and Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cq10ovAX6daY"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPKBWWuNpSuP7DHsa+Zpo3l",
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
